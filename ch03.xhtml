<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd"
  xmlns:epub="http://www.idpf.org/2007/ops">

<head>
  <link href="Style00.css" rel="stylesheet" type="text/css" />
  <link href="Style01.css" rel="stylesheet" type="text/css" />
  <link href="Style02.css" rel="stylesheet" type="text/css" />
  <link href="Style03.css" rel="stylesheet" type="text/css" />
  <style type="text/css" title="ibis-book">
    @charset "utf-8";

    #sbo-rt-content html,
    #sbo-rt-content div,
    #sbo-rt-content div,
    #sbo-rt-content span,
    #sbo-rt-content applet,
    #sbo-rt-content object,
    #sbo-rt-content iframe,
    #sbo-rt-content h1,
    #sbo-rt-content h2,
    #sbo-rt-content h3,
    #sbo-rt-content h4,
    #sbo-rt-content h5,
    #sbo-rt-content h6,
    #sbo-rt-content p,
    #sbo-rt-content blockquote,
    #sbo-rt-content pre,
    #sbo-rt-content a,
    #sbo-rt-content abbr,
    #sbo-rt-content acronym,
    #sbo-rt-content address,
    #sbo-rt-content big,
    #sbo-rt-content cite,
    #sbo-rt-content code,
    #sbo-rt-content del,
    #sbo-rt-content dfn,
    #sbo-rt-content em,
    #sbo-rt-content img,
    #sbo-rt-content ins,
    #sbo-rt-content kbd,
    #sbo-rt-content q,
    #sbo-rt-content s,
    #sbo-rt-content samp,
    #sbo-rt-content small,
    #sbo-rt-content strike,
    #sbo-rt-content strong,
    #sbo-rt-content sub,
    #sbo-rt-content sup,
    #sbo-rt-content tt,
    #sbo-rt-content var,
    #sbo-rt-content b,
    #sbo-rt-content u,
    #sbo-rt-content i,
    #sbo-rt-content center,
    #sbo-rt-content dl,
    #sbo-rt-content dt,
    #sbo-rt-content dd,
    #sbo-rt-content ol,
    #sbo-rt-content ul,
    #sbo-rt-content li,
    #sbo-rt-content fieldset,
    #sbo-rt-content form,
    #sbo-rt-content label,
    #sbo-rt-content legend,
    #sbo-rt-content table,
    #sbo-rt-content caption,
    #sbo-rt-content tdiv,
    #sbo-rt-content tfoot,
    #sbo-rt-content thead,
    #sbo-rt-content tr,
    #sbo-rt-content th,
    #sbo-rt-content td,
    #sbo-rt-content article,
    #sbo-rt-content aside,
    #sbo-rt-content canvas,
    #sbo-rt-content details,
    #sbo-rt-content embed,
    #sbo-rt-content figure,
    #sbo-rt-content figcaption,
    #sbo-rt-content footer,
    #sbo-rt-content header,
    #sbo-rt-content hgroup,
    #sbo-rt-content menu,
    #sbo-rt-content nav,
    #sbo-rt-content output,
    #sbo-rt-content ruby,
    #sbo-rt-content section,
    #sbo-rt-content summary,
    #sbo-rt-content time,
    #sbo-rt-content mark,
    #sbo-rt-content audio,
    #sbo-rt-content video {
      margin: 0;
      padding: 0;
      border: 0;
      font-size: 100%;
      font: inherit;
      vertical-align: baseline
    }

    #sbo-rt-content article,
    #sbo-rt-content aside,
    #sbo-rt-content details,
    #sbo-rt-content figcaption,
    #sbo-rt-content figure,
    #sbo-rt-content footer,
    #sbo-rt-content header,
    #sbo-rt-content hgroup,
    #sbo-rt-content menu,
    #sbo-rt-content nav,
    #sbo-rt-content section {
      display: block
    }

    #sbo-rt-content div {
      line-height: 1
    }

    #sbo-rt-content ol,
    #sbo-rt-content ul {
      list-style: none
    }

    #sbo-rt-content blockquote,
    #sbo-rt-content q {
      quotes: none
    }

    #sbo-rt-content blockquote:before,
    #sbo-rt-content blockquote:after,
    #sbo-rt-content q:before,
    #sbo-rt-content q:after {
      content: none
    }

    #sbo-rt-content table {
      border-collapse: collapse;
      border-spacing: 0
    }

    @page {
      margin: 5px !important
    }

    #sbo-rt-content p {
      margin: 10px 0 0;
      line-height: 125%;
      text-align: left
    }

    #sbo-rt-content p.byline {
      text-align: left;
      margin: -33px auto 35px;
      font-style: italic;
      font-weight: bold
    }

    #sbo-rt-content div.preface p+p.byline {
      margin: 1em 0 0 !important
    }

    #sbo-rt-content div.preface p.byline+p.byline {
      margin: 0 !important
    }

    #sbo-rt-content div.sect1&gt;

    p.byline {
      margin: -.25em 0 1em
    }

    #sbo-rt-content div.sect1&gt;

    p.byline+p.byline {
      margin-top: -1em
    }

    #sbo-rt-content em {
      font-style: italic;
      font-family: inherit
    }

    #sbo-rt-content em strong,
    #sbo-rt-content strong em {
      font-weight: bold;
      font-style: italic;
      font-family: inherit
    }

    #sbo-rt-content strong,
    #sbo-rt-content span.bold {
      font-weight: bold
    }

    #sbo-rt-content em.replaceable {
      font-style: italic
    }

    #sbo-rt-content strong.userinput {
      font-weight: bold;
      font-style: normal
    }

    #sbo-rt-content span.bolditalic {
      font-weight: bold;
      font-style: italic
    }

    #sbo-rt-content a.ulink,
    #sbo-rt-content a.xref,
    #sbo-rt-content a.email,
    #sbo-rt-content a.link,
    #sbo-rt-content a {
      text-decoration: none;
      color: #8e0012
    }

    #sbo-rt-content span.lineannotation {
      font-style: italic;
      color: #a62a2a;
      font-family: serif
    }

    #sbo-rt-content span.underline {
      text-decoration: underline
    }

    #sbo-rt-content span.strikethrough {
      text-decoration: line-through
    }

    #sbo-rt-content span.smallcaps {
      font-variant: small-caps
    }

    #sbo-rt-content span.cursor {
      background: #000;
      color: #fff
    }

    #sbo-rt-content span.smaller {
      font-size: 75%
    }

    #sbo-rt-content .boxedtext,
    #sbo-rt-content .keycap {
      border-style: solid;
      border-width: 1px;
      border-color: #000;
      padding: 1px
    }

    #sbo-rt-content span.gray50 {
      color: #7F7F7F;
    }

    #sbo-rt-content h1,
    #sbo-rt-content div.toc-title,
    #sbo-rt-content h2,
    #sbo-rt-content h3,
    #sbo-rt-content h4,
    #sbo-rt-content h5 {
      -webkit-hyphens: none;
      hyphens: none;
      adobe-hyphenate: none;
      font-weight: bold;
      text-align: left;
      page-break-after: avoid !important;
      font-family: sans-serif, "DejaVuSans"
    }

    #sbo-rt-content div.toc-title {
      font-size: 1.5em;
      margin-top: 20px !important;
      margin-bottom: 30px !important
    }

    #sbo-rt-content section[data-type="sect1"] h1 {
      font-size: 1.3em;
      color: #8e0012;
      margin: 40px 0 8px 0
    }

    #sbo-rt-content section[data-type="sect2"] h2 {
      font-size: 1.1em;
      margin: 30px 0 8px 0 !important
    }

    #sbo-rt-content section[data-type="sect3"] h3 {
      font-size: 1em;
      color: #555;
      margin: 20px 0 8px 0 !important
    }

    #sbo-rt-content section[data-type="sect4"] h4 {
      font-size: 1em;
      font-weight: normal;
      font-style: italic;
      margin: 15px 0 6px 0 !important
    }

    #sbo-rt-content section[data-type="chapter"]&gt;
    div&gt;
    h1,
    #sbo-rt-content section[data-type="preface"]&gt;
    div&gt;
    h1,
    #sbo-rt-content section[data-type="appendix"]&gt;
    div&gt;
    h1,
    #sbo-rt-content section[data-type="glossary"]&gt;
    div&gt;
    h1,
    #sbo-rt-content section[data-type="bibliography"]&gt;
    div&gt;
    h1,
    #sbo-rt-content section[data-type="index"]&gt;
    div&gt;

    h1 {
      font-size: 2em;
      line-height: 1;
      margin-bottom: 50px;
      color: #000;
      padding-bottom: 10px;
      border-bottom: 1px solid #000
    }

    #sbo-rt-content span.label,
    #sbo-rt-content span.keep-together {
      font-size: inherit;
      font-weight: inherit
    }

    #sbo-rt-content div[data-type="part"] h1 {
      font-size: 2em;
      text-align: center;
      margin-top: 0 !important;
      margin-bottom: 50px;
      padding: 50px 0 10px 0;
      border-bottom: 1px solid #000
    }

    #sbo-rt-content img.width-ninety {
      width: 90%
    }

    #sbo-rt-content img {
      max-width: 95%;
      margin: 0 auto;
      padding: 0
    }

    #sbo-rt-content div.figure {
      background-color: transparent;
      text-align: center !important;
      margin: 15px 0 15px 0 !important;
      page-break-inside: avoid
    }

    #sbo-rt-content figure {
      margin: 15px 0 15px 0 !important;
      page-break-inside: avoid
    }

    #sbo-rt-content div.figure h6,
    #sbo-rt-content figure h6,
    #sbo-rt-content figure figcaption {
      font-size: .9rem !important;
      text-align: center;
      font-weight: normal !important;
      font-style: italic;
      font-family: serif !important;
      text-transform: none !important;
      letter-spacing: normal !important;
      color: #000 !important;
      padding-top: 10px !important;
      page-break-before: avoid
    }

    #sbo-rt-content div.informalfigure {
      text-align: center !important;
      padding: 5px 0 !important
    }

    #sbo-rt-content div.sidebar {
      margin: 15px 0 10px 0 !important;
      border: 1px solid #DCDCDC;
      background-color: #F7F7F7;
      padding: 15px !important;
      page-break-inside: avoid
    }

    #sbo-rt-content aside[data-type="sidebar"] {
      margin: 15px 0 10px 0 !important;
      page-break-inside: avoid
    }

    #sbo-rt-content div.sidebar-title,
    #sbo-rt-content aside[data-type="sidebar"] h5 {
      font-weight: bold;
      font-size: 1em;
      font-family: sans-serif;
      text-transform: uppercase;
      letter-spacing: 1px;
      text-align: center;
      margin: 4px 0 6px 0 !important;
      page-break-inside: avoid
    }

    #sbo-rt-content div.sidebar ol,
    #sbo-rt-content div.sidebar ul,
    #sbo-rt-content aside[data-type="sidebar"] ol,
    #sbo-rt-content aside[data-type="sidebar"] ul {
      margin-left: 1.25em !important
    }

    #sbo-rt-content div.sidebar div.figure p.title,
    #sbo-rt-content aside[data-type="sidebar"] figcaption,
    #sbo-rt-content div.sidebar div.informalfigure div.caption {
      font-size: 90%;
      text-align: center;
      font-weight: normal;
      font-style: italic;
      font-family: serif !important;
      color: #000;
      padding: 5px !important;
      page-break-before: avoid;
      page-break-after: avoid
    }

    #sbo-rt-content div.sidebar div.tip,
    #sbo-rt-content div.sidebar div[data-type="tip"],
    #sbo-rt-content div.sidebar div.note,
    #sbo-rt-content div.sidebar div[data-type="note"],
    #sbo-rt-content div.sidebar div.warning,
    #sbo-rt-content div.sidebar div[data-type="warning"],
    #sbo-rt-content div.sidebar div[data-type="caution"],
    #sbo-rt-content div.sidebar div[data-type="important"] {
      margin: 20px auto 20px auto !important;
      font-size: 90%;
      width: 85%
    }

    #sbo-rt-content aside[data-type="sidebar"] p.byline {
      font-size: 90%;
      font-weight: bold;
      font-style: italic;
      text-align: center;
      text-indent: 0;
      margin: 5px auto 6px;
      page-break-after: avoid
    }

    #sbo-rt-content pre {
      white-space: pre-wrap;
      font-family: "Ubuntu Mono", monospace;
      margin: 25px 0 25px 20px;
      font-size: 85%;
      display: block;
      -webkit-hyphens: none;
      hyphens: none;
      adobe-hyphenate: none;
      overflow-wrap: break-word
    }

    #sbo-rt-content div.note pre.programlisting,
    #sbo-rt-content div.tip pre.programlisting,
    #sbo-rt-content div.warning pre.programlisting,
    #sbo-rt-content div.caution pre.programlisting,
    #sbo-rt-content div.important pre.programlisting {
      margin-bottom: 0
    }

    #sbo-rt-content code {
      font-family: "Ubuntu Mono", monospace;
      -webkit-hyphens: none;
      hyphens: none;
      adobe-hyphenate: none;
      overflow-wrap: break-word
    }

    #sbo-rt-content code strong em,
    #sbo-rt-content code em strong,
    #sbo-rt-content pre em strong,
    #sbo-rt-content pre strong em,
    #sbo-rt-content strong code em code,
    #sbo-rt-content em code strong code,
    #sbo-rt-content span.bolditalic code {
      font-weight: bold;
      font-style: italic;
      font-family: "Ubuntu Mono BoldItal", monospace
    }

    #sbo-rt-content code em,
    #sbo-rt-content em code,
    #sbo-rt-content pre em,
    #sbo-rt-content em.replaceable {
      font-family: "Ubuntu Mono Ital", monospace;
      font-style: italic
    }

    #sbo-rt-content code strong,
    #sbo-rt-content strong code,
    #sbo-rt-content pre strong,
    #sbo-rt-content strong.userinput {
      font-family: "Ubuntu Mono Bold", monospace;
      font-weight: bold
    }

    #sbo-rt-content div[data-type="example"] {
      margin: 10px 0 15px 0 !important
    }

    #sbo-rt-content div[data-type="example"] h1,
    #sbo-rt-content div[data-type="example"] h2,
    #sbo-rt-content div[data-type="example"] h3,
    #sbo-rt-content div[data-type="example"] h4,
    #sbo-rt-content div[data-type="example"] h5,
    #sbo-rt-content div[data-type="example"] h6 {
      font-style: italic;
      font-weight: normal;
      text-align: left !important;
      text-transform: none !important;
      font-family: serif !important;
      margin: 10px 0 5px 0 !important;
      border-bottom: 1px solid #000
    }

    #sbo-rt-content li pre.example {
      padding: 10px 0 !important
    }

    #sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],
    #sbo-rt-content div[data-type="example"] pre[data-type="screen"] {
      margin: 0
    }

    #sbo-rt-content section[data-type="titlepage"]&gt;
    div&gt;

    h1 {
      font-size: 2em;
      margin: 50px 0 10px 0 !important;
      line-height: 1;
      text-align: center
    }

    #sbo-rt-content section[data-type="titlepage"] h2,
    #sbo-rt-content section[data-type="titlepage"] p.subtitle,
    #sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"] {
      font-size: 1.3em;
      font-weight: normal;
      text-align: center;
      margin-top: .5em;
      color: #555
    }

    #sbo-rt-content section[data-type="titlepage"]&gt;
    div&gt;

    h2[data-type="author"],
    #sbo-rt-content section[data-type="titlepage"] p.author {
      font-size: 1.3em;
      font-family: serif !important;
      font-weight: bold;
      margin: 50px 0 !important;
      text-align: center
    }

    #sbo-rt-content section[data-type="titlepage"] p.edition {
      text-align: center;
      text-transform: uppercase;
      margin-top: 2em
    }

    #sbo-rt-content section[data-type="titlepage"] {
      text-align: center
    }

    #sbo-rt-content section[data-type="titlepage"]:after {
      content: url(css_assets/titlepage_footer_ebook.png);
      margin: 0 auto;
      max-width: 80%
    }

    #sbo-rt-content div.book div.titlepage div.publishername {
      margin-top: 60%;
      margin-bottom: 20px;
      text-align: center;
      font-size: 1.25em
    }

    #sbo-rt-content div.book div.titlepage div.locations p {
      margin: 0;
      text-align: center
    }

    #sbo-rt-content div.book div.titlepage div.locations p.cities {
      font-size: 80%;
      text-align: center;
      margin-top: 5px
    }

    #sbo-rt-content section.preface[title="Dedication"]&gt;

    div.titlepage h2.title {
      text-align: center;
      text-transform: uppercase;
      font-size: 1.5em;
      margin-top: 50px;
      margin-bottom: 50px
    }

    #sbo-rt-content ul.stafflist {
      margin: 15px 0 15px 20px !important
    }

    #sbo-rt-content ul.stafflist li {
      list-style-type: none;
      padding: 5px 0
    }

    #sbo-rt-content ul.printings li {
      list-style-type: none
    }

    #sbo-rt-content section.preface[title="Dedication"] p {
      font-style: italic;
      text-align: center
    }

    #sbo-rt-content div.colophon h1.title {
      font-size: 1.3em;
      margin: 0 !important;
      font-family: serif !important;
      font-weight: normal
    }

    #sbo-rt-content div.colophon h2.subtitle {
      margin: 0 !important;
      color: #000;
      font-family: serif !important;
      font-size: 1em;
      font-weight: normal
    }

    #sbo-rt-content div.colophon div.author h3.author {
      font-size: 1.1em;
      font-family: serif !important;
      margin: 10px 0 0 !important;
      font-weight: normal
    }

    #sbo-rt-content div.colophon div.editor h4,
    #sbo-rt-content div.colophon div.editor h3.editor {
      color: #000;
      font-size: .8em;
      margin: 15px 0 0 !important;
      font-family: serif !important;
      font-weight: normal
    }

    #sbo-rt-content div.colophon div.editor h3.editor {
      font-size: .8em;
      margin: 0 !important;
      font-family: serif !important;
      font-weight: normal
    }

    #sbo-rt-content div.colophon div.publisher {
      margin-top: 10px
    }

    #sbo-rt-content div.colophon div.publisher p,
    #sbo-rt-content div.colophon div.publisher span.publishername {
      margin: 0;
      font-size: .8em
    }

    #sbo-rt-content div.legalnotice p,
    #sbo-rt-content div.timestamp p {
      font-size: .8em
    }

    #sbo-rt-content div.timestamp p {
      margin-top: 10px
    }

    #sbo-rt-content div.colophon[title="About the Author"] h1.title,
    #sbo-rt-content div.colophon[title="Colophon"] h1.title {
      font-size: 1.5em;
      margin: 0 !important;
      font-family: sans-serif !important
    }

    #sbo-rt-content section.chapter div.titlepage div.author {
      margin: 10px 0 10px 0
    }

    #sbo-rt-content section.chapter div.titlepage div.author div.affiliation {
      font-style: italic
    }

    #sbo-rt-content div.attribution {
      margin: 5px 0 0 50px !important
    }

    #sbo-rt-content h3.author span.orgname {
      display: none
    }

    #sbo-rt-content div.epigraph {
      margin: 10px 0 10px 20px !important;
      page-break-inside: avoid;
      font-size: 90%
    }

    #sbo-rt-content div.epigraph p {
      font-style: italic
    }

    #sbo-rt-content blockquote,
    #sbo-rt-content div.blockquote {
      margin: 10px !important;
      page-break-inside: avoid;
      font-size: 95%
    }

    #sbo-rt-content blockquote p,
    #sbo-rt-content div.blockquote p {
      font-style: italic;
      margin: .75em 0 0 !important
    }

    #sbo-rt-content blockquote div.attribution,
    #sbo-rt-content blockquote p[data-type="attribution"] {
      margin: 5px 0 10px 30px !important;
      text-align: right;
      width: 80%
    }

    #sbo-rt-content blockquote div.attribution p,
    #sbo-rt-content blockquote p[data-type="attribution"] {
      font-style: normal;
      margin-top: 5px
    }

    #sbo-rt-content blockquote div.attribution p:before,
    #sbo-rt-content blockquote p[data-type="attribution"]:before {
      font-style: normal;
      content: "—";
      -webkit-hyphens: none;
      hyphens: none;
      adobe-hyphenate: none
    }

    #sbo-rt-content p.right {
      text-align: right;
      margin: 0
    }

    #sbo-rt-content div[data-type="footnotes"] {
      border-top: 1px solid black;
      margin-top: 2em
    }

    #sbo-rt-content sub,
    #sbo-rt-content sup {
      font-size: 75%;
      line-height: 0;
      position: relative
    }

    #sbo-rt-content sup {
      top: -.5em
    }

    #sbo-rt-content sub {
      bottom: -.25em
    }

    #sbo-rt-content p[data-type="footnote"] {
      font-size: 90% !important;
      line-height: 1.2em !important;
      margin-left: 2.5em !important;
      text-indent: -2.3em !important
    }

    #sbo-rt-content p[data-type="footnote"] sup {
      display: inline-block !important;
      position: static !important;
      width: 2em !important;
      text-align: right !important;
      font-size: 100% !important;
      padding-right: .5em !important
    }

    #sbo-rt-content p[data-type="footnote"] a[href$="-marker"] {
      font-family: sans-serif !important;
      font-size: 90% !important;
      color: #8e0012 !important
    }

    #sbo-rt-content a[data-type="noteref"] {
      font-family: sans-serif !important;
      color: #8e0012;
      margin-left: 0;
      padding-left: 0
    }

    #sbo-rt-content div.refentry p.refname {
      font-size: 1em;
      font-family: sans-serif, "DejaVuSans";
      font-weight: bold;
      margin-bottom: 5px;
      overflow: auto;
      width: 100%
    }

    #sbo-rt-content div.refentry {
      width: 100%;
      display: block;
      margin-top: 2em
    }

    #sbo-rt-content div.refsynopsisdiv {
      display: block;
      clear: both
    }

    #sbo-rt-content div.refentry header {
      page-break-inside: avoid !important;
      display: block;
      break-inside: avoid !important;
      padding-top: 0;
      border-bottom: 1px solid #000
    }

    #sbo-rt-content div.refsect1 h6 {
      font-size: .9em;
      font-family: sans-serif, "DejaVuSans";
      font-weight: bold
    }

    #sbo-rt-content div.refsect1 {
      margin-top: 3em
    }

    #sbo-rt-content dt {
      padding-top: 10px !important;
      padding-bottom: 0 !important
    }

    #sbo-rt-content dd {
      margin-left: 1.5em !important;
      margin-bottom: .25em
    }

    #sbo-rt-content dd ol,
    #sbo-rt-content dd ul {
      padding-left: 1em
    }

    #sbo-rt-content dd li {
      margin-top: 0;
      margin-bottom: 0
    }

    #sbo-rt-content dd,
    #sbo-rt-content li {
      text-align: left
    }

    #sbo-rt-content ul,
    #sbo-rt-content ul&gt;
    li,
    #sbo-rt-content ol ul,
    #sbo-rt-content ol ul&gt;
    li,
    #sbo-rt-content ul ol ul,
    #sbo-rt-content ul ol ul&gt;

    li {
      list-style-type: disc
    }

    #sbo-rt-content ul ul,
    #sbo-rt-content ul ul&gt;

    li {
      list-style-type: square
    }

    #sbo-rt-content ul ul ul,
    #sbo-rt-content ul ul ul&gt;

    li {
      list-style-type: circle
    }

    #sbo-rt-content ol,
    #sbo-rt-content ol&gt;
    li,
    #sbo-rt-content ol ul ol,
    #sbo-rt-content ol ul ol&gt;
    li,
    #sbo-rt-content ul ol,
    #sbo-rt-content ul ol&gt;

    li {
      list-style-type: decimal
    }

    #sbo-rt-content ol ol,
    #sbo-rt-content ol ol&gt;

    li {
      list-style-type: lower-alpha
    }

    #sbo-rt-content ol ol ol,
    #sbo-rt-content ol ol ol&gt;

    li {
      list-style-type: lower-roman
    }

    #sbo-rt-content ol,
    #sbo-rt-content ul {
      list-style-position: outside;
      margin: 15px 0 15px 1.25em;
      padding-left: 2.25em
    }

    #sbo-rt-content ol li,
    #sbo-rt-content ul li {
      margin: .5em 0 .65em;
      line-height: 125%
    }

    #sbo-rt-content div.orderedlistalpha {
      list-style-type: upper-alpha
    }

    #sbo-rt-content table.simplelist,
    #sbo-rt-content ul.simplelist {
      margin: 15px 0 15px 20px !important
    }

    #sbo-rt-content ul.simplelist li {
      list-style-type: none;
      padding: 5px 0
    }

    #sbo-rt-content table.simplelist td {
      border: none
    }

    #sbo-rt-content table.simplelist tr {
      border-bottom: none
    }

    #sbo-rt-content table.simplelist tr:nth-of-type(even) {
      background-color: transparent
    }

    #sbo-rt-content dl.calloutlist p:first-child {
      margin-top: -25px !important
    }

    #sbo-rt-content dl.calloutlist dd {
      padding-left: 0;
      margin-top: -25px
    }

    #sbo-rt-content dl.calloutlist img,
    #sbo-rt-content a.co img {
      padding: 0
    }

    #sbo-rt-content div.toc ol {
      margin-top: 8px !important;
      margin-bottom: 8px !important;
      margin-left: 0 !important;
      padding-left: 0 !important
    }

    #sbo-rt-content div.toc ol ol {
      margin-left: 30px !important;
      padding-left: 0 !important
    }

    #sbo-rt-content div.toc ol li {
      list-style-type: none
    }

    #sbo-rt-content div.toc a {
      color: #8e0012
    }

    #sbo-rt-content div.toc ol a {
      font-size: 1em;
      font-weight: bold
    }

    #sbo-rt-content div.toc ol&gt;
    li&gt;

    ol a {
      font-weight: bold;
      font-size: 1em
    }

    #sbo-rt-content div.toc ol&gt;
    li&gt;
    ol&gt;
    li&gt;

    ol a {
      text-decoration: none;
      font-weight: normal;
      font-size: 1em
    }

    #sbo-rt-content div.tip,
    #sbo-rt-content div[data-type="tip"],
    #sbo-rt-content div.note,
    #sbo-rt-content div[data-type="note"],
    #sbo-rt-content div.warning,
    #sbo-rt-content div[data-type="warning"],
    #sbo-rt-content div[data-type="caution"],
    #sbo-rt-content div[data-type="important"] {
      margin: 30px !important;
      font-size: 90%;
      padding: 10px 8px 20px 8px !important;
      page-break-inside: avoid
    }

    #sbo-rt-content div.tip ol,
    #sbo-rt-content div.tip ul,
    #sbo-rt-content div[data-type="tip"] ol,
    #sbo-rt-content div[data-type="tip"] ul,
    #sbo-rt-content div.note ol,
    #sbo-rt-content div.note ul,
    #sbo-rt-content div[data-type="note"] ol,
    #sbo-rt-content div[data-type="note"] ul,
    #sbo-rt-content div.warning ol,
    #sbo-rt-content div.warning ul,
    #sbo-rt-content div[data-type="warning"] ol,
    #sbo-rt-content div[data-type="warning"] ul,
    #sbo-rt-content div[data-type="caution"] ol,
    #sbo-rt-content div[data-type="caution"] ul,
    #sbo-rt-content div[data-type="important"] ol,
    #sbo-rt-content div[data-type="important"] ul {
      margin-left: 1.5em !important
    }

    #sbo-rt-content div.tip,
    #sbo-rt-content div[data-type="tip"],
    #sbo-rt-content div.note,
    #sbo-rt-content div[data-type="note"] {
      border: 1px solid #BEBEBE;
      background-color: transparent
    }

    #sbo-rt-content div.warning,
    #sbo-rt-content div[data-type="warning"],
    #sbo-rt-content div[data-type="caution"],
    #sbo-rt-content div[data-type="important"] {
      border: 1px solid #BC8F8F
    }

    #sbo-rt-content div.tip h3,
    #sbo-rt-content div[data-type="tip"] h6,
    #sbo-rt-content div[data-type="tip"] h1,
    #sbo-rt-content div.note h3,
    #sbo-rt-content div[data-type="note"] h6,
    #sbo-rt-content div[data-type="note"] h1,
    #sbo-rt-content div.warning h3,
    #sbo-rt-content div[data-type="warning"] h6,
    #sbo-rt-content div[data-type="warning"] h1,
    #sbo-rt-content div[data-type="caution"] h6,
    #sbo-rt-content div[data-type="caution"] h1,
    #sbo-rt-content div[data-type="important"] h1,
    #sbo-rt-content div[data-type="important"] h6 {
      font-weight: bold;
      font-size: 110%;
      font-family: sans-serif !important;
      text-transform: uppercase;
      letter-spacing: 1px;
      text-align: center;
      margin: 4px 0 6px !important
    }

    #sbo-rt-content div[data-type="tip"] figure h6,
    #sbo-rt-content div[data-type="note"] figure h6,
    #sbo-rt-content div[data-type="warning"] figure h6,
    #sbo-rt-content div[data-type="caution"] figure h6,
    #sbo-rt-content div[data-type="important"] figure h6 {
      font-family: serif !important
    }

    #sbo-rt-content div.tip h3,
    #sbo-rt-content div[data-type="tip"] h6,
    #sbo-rt-content div.note h3,
    #sbo-rt-content div[data-type="note"] h6,
    #sbo-rt-content div[data-type="tip"] h1,
    #sbo-rt-content div[data-type="note"] h1 {
      color: #737373
    }

    #sbo-rt-content div.warning h3,
    #sbo-rt-content div[data-type="warning"] h6,
    #sbo-rt-content div[data-type="caution"] h6,
    #sbo-rt-content div[data-type="important"] h6,
    #sbo-rt-content div[data-type="warning"] h1,
    #sbo-rt-content div[data-type="caution"] h1,
    #sbo-rt-content div[data-type="important"] h1 {
      color: #C67171
    }

    #sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,
    #sbo-rt-content div.safarienabled {
      background-color: transparent;
      margin: 8px 0 0 !important;
      border: 0 solid #BEBEBE;
      font-size: 100%;
      padding: 0 !important;
      page-break-inside: avoid
    }

    #sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,
    #sbo-rt-content div.safarienabled h6 {
      display: none
    }

    #sbo-rt-content div.table,
    #sbo-rt-content table {
      margin: 15px 0 30px 0 !important;
      max-width: 95%;
      border: none !important;
      background: none;
      display: table !important
    }

    #sbo-rt-content div.table,
    #sbo-rt-content div.informaltable,
    #sbo-rt-content table {
      page-break-inside: avoid
    }

    #sbo-rt-content tr,
    #sbo-rt-content tr td {
      border-bottom: 1px solid #c3c3c3
    }

    #sbo-rt-content thead td,
    #sbo-rt-content thead th {
      border-bottom: #9d9d9d 1px solid !important;
      border-top: #9d9d9d 1px solid !important
    }

    #sbo-rt-content tr:nth-of-type(even) {
      background-color: #f1f6fc
    }

    #sbo-rt-content thead {
      font-family: sans-serif;
      font-weight: bold
    }

    #sbo-rt-content td,
    #sbo-rt-content th {
      display: table-cell;
      padding: .3em;
      text-align: left;
      vertical-align: middle;
      font-size: 80%
    }

    #sbo-rt-content div.informaltable table {
      margin: 10px auto !important
    }

    #sbo-rt-content div.informaltable table tr {
      border-bottom: none
    }

    #sbo-rt-content div.informaltable table tr:nth-of-type(even) {
      background-color: transparent
    }

    #sbo-rt-content div.informaltable td,
    #sbo-rt-content div.informaltable th {
      border: #9d9d9d 1px solid
    }

    #sbo-rt-content div.table-title,
    #sbo-rt-content table caption {
      font-weight: normal;
      font-style: italic;
      font-family: serif;
      font-size: 1em;
      margin: 10px 0 10px 0 !important;
      padding: 0;
      page-break-after: avoid;
      text-align: left !important
    }

    #sbo-rt-content table code {
      font-size: smaller
    }

    #sbo-rt-content table.border tbody&gt;
    tr:last-child&gt;

    td {
      border-bottom: transparent
    }

    #sbo-rt-content div.equation,
    #sbo-rt-content div[data-type="equation"] {
      margin: 10px 0 15px 0 !important
    }

    #sbo-rt-content div.equation-title,
    #sbo-rt-content div[data-type="equation"] h5 {
      font-style: italic;
      font-weight: normal;
      font-family: serif !important;
      font-size: 90%;
      margin: 20px 0 10px 0 !important;
      page-break-after: avoid
    }

    #sbo-rt-content div.equation-contents {
      margin-left: 20px
    }

    #sbo-rt-content div[data-type="equation"] math {
      font-size: calc(.35em + 1vw)
    }

    #sbo-rt-content span.inlinemediaobject {
      height: .85em;
      display: inline-block;
      margin-bottom: .2em
    }

    #sbo-rt-content span.inlinemediaobject img {
      margin: 0;
      height: .85em
    }

    #sbo-rt-content div.informalequation {
      margin: 20px 0 20px 20px;
      width: 75%
    }

    #sbo-rt-content div.informalequation img {
      width: 75%
    }

    #sbo-rt-content div.index {
      text-indent: 0
    }

    #sbo-rt-content div.index h3 {
      padding: .25em;
      margin-top: 1em !important;
      background-color: #F0F0F0
    }

    #sbo-rt-content div.index li {
      line-height: 130%;
      list-style-type: none
    }

    #sbo-rt-content div.index a.indexterm {
      color: #8e0012 !important
    }

    #sbo-rt-content div.index ul {
      margin-left: 0 !important;
      padding-left: 0 !important
    }

    #sbo-rt-content div.index ul ul {
      margin-left: 1em !important;
      margin-top: 0 !important
    }

    #sbo-rt-content code.boolean,
    #sbo-rt-content .navy {
      color: rgb(0, 0, 128);
    }

    #sbo-rt-content code.character,
    #sbo-rt-content .olive {
      color: rgb(128, 128, 0);
    }

    #sbo-rt-content code.comment,
    #sbo-rt-content .blue {
      color: rgb(0, 0, 255);
    }

    #sbo-rt-content code.conditional,
    #sbo-rt-content .limegreen {
      color: rgb(50, 205, 50);
    }

    #sbo-rt-content code.constant,
    #sbo-rt-content .darkorange {
      color: rgb(255, 140, 0);
    }

    #sbo-rt-content code.debug,
    #sbo-rt-content .darkred {
      color: rgb(139, 0, 0);
    }

    #sbo-rt-content code.define,
    #sbo-rt-content .darkgoldenrod,
    #sbo-rt-content .gold {
      color: rgb(184, 134, 11);
    }

    #sbo-rt-content code.delimiter,
    #sbo-rt-content .dimgray {
      color: rgb(105, 105, 105);
    }

    #sbo-rt-content code.error,
    #sbo-rt-content .red {
      color: rgb(255, 0, 0);
    }

    #sbo-rt-content code.exception,
    #sbo-rt-content .salmon {
      color: rgb(250, 128, 11);
    }

    #sbo-rt-content code.float,
    #sbo-rt-content .steelblue {
      color: rgb(70, 130, 180);
    }

    #sbo-rt-content pre code.function,
    #sbo-rt-content .green {
      color: rgb(0, 128, 0);
    }

    #sbo-rt-content code.identifier,
    #sbo-rt-content .royalblue {
      color: rgb(65, 105, 225);
    }

    #sbo-rt-content code.ignore,
    #sbo-rt-content .gray {
      color: rgb(128, 128, 128);
    }

    #sbo-rt-content code.include,
    #sbo-rt-content .purple {
      color: rgb(128, 0, 128);
    }

    #sbo-rt-content code.keyword,
    #sbo-rt-content .sienna {
      color: rgb(160, 82, 45);
    }

    #sbo-rt-content code.label,
    #sbo-rt-content .deeppink {
      color: rgb(255, 20, 147);
    }

    #sbo-rt-content code.macro,
    #sbo-rt-content .orangered {
      color: rgb(255, 69, 0);
    }

    #sbo-rt-content code.number,
    #sbo-rt-content .brown {
      color: rgb(165, 42, 42);
    }

    #sbo-rt-content code.operator,
    #sbo-rt-content .black {
      color: #000;
    }

    #sbo-rt-content code.preCondit,
    #sbo-rt-content .teal {
      color: rgb(0, 128, 128);
    }

    #sbo-rt-content code.preProc,
    #sbo-rt-content .fuschia {
      color: rgb(255, 0, 255);
    }

    #sbo-rt-content code.repeat,
    #sbo-rt-content .indigo {
      color: rgb(75, 0, 130);
    }

    #sbo-rt-content code.special,
    #sbo-rt-content .saddlebrown {
      color: rgb(139, 69, 19);
    }

    #sbo-rt-content code.specialchar,
    #sbo-rt-content .magenta {
      color: rgb(255, 0, 255);
    }

    #sbo-rt-content code.specialcomment,
    #sbo-rt-content .seagreen {
      color: rgb(46, 139, 87);
    }

    #sbo-rt-content code.statement,
    #sbo-rt-content .forestgreen {
      color: rgb(34, 139, 34);
    }

    #sbo-rt-content code.storageclass,
    #sbo-rt-content .plum {
      color: rgb(221, 160, 221);
    }

    #sbo-rt-content code.string,
    #sbo-rt-content .darkred {
      color: rgb(139, 0, 0);
    }

    #sbo-rt-content code.structure,
    #sbo-rt-content .chocolate {
      color: rgb(210, 106, 30);
    }

    #sbo-rt-content code.tag,
    #sbo-rt-content .darkcyan {
      color: rgb(0, 139, 139);
    }

    #sbo-rt-content code.todo,
    #sbo-rt-content .black {
      color: #000;
    }

    #sbo-rt-content code.type,
    #sbo-rt-content .mediumslateblue {
      color: rgb(123, 104, 238);
    }

    #sbo-rt-content code.typedef,
    #sbo-rt-content .darkgreen {
      color: rgb(0, 100, 0);
    }

    #sbo-rt-content code.underlined {
      text-decoration: underline;
    }

    #sbo-rt-content pre code.hll {
      background-color: #ffc
    }

    #sbo-rt-content pre code.c {
      color: #09F;
      font-style: italic
    }

    #sbo-rt-content pre code.err {
      color: #A00
    }

    #sbo-rt-content pre code.k {
      color: #069;
      font-weight: bold
    }

    #sbo-rt-content pre code.o {
      color: #555
    }

    #sbo-rt-content pre code.cm {
      color: #35586C;
      font-style: italic
    }

    #sbo-rt-content pre code.cp {
      color: #099
    }

    #sbo-rt-content pre code.c1 {
      color: #35586C;
      font-style: italic
    }

    #sbo-rt-content pre code.cs {
      color: #35586C;
      font-weight: bold;
      font-style: italic
    }

    #sbo-rt-content pre code.gd {
      background-color: #FCC
    }

    #sbo-rt-content pre code.ge {
      font-style: italic
    }

    #sbo-rt-content pre code.gr {
      color: #F00
    }

    #sbo-rt-content pre code.gh {
      color: #030;
      font-weight: bold
    }

    #sbo-rt-content pre code.gi {
      background-color: #CFC
    }

    #sbo-rt-content pre code.go {
      color: #000
    }

    #sbo-rt-content pre code.gp {
      color: #009;
      font-weight: bold
    }

    #sbo-rt-content pre code.gs {
      font-weight: bold
    }

    #sbo-rt-content pre code.gu {
      color: #030;
      font-weight: bold
    }

    #sbo-rt-content pre code.gt {
      color: #9C6
    }

    #sbo-rt-content pre code.kc {
      color: #069;
      font-weight: bold
    }

    #sbo-rt-content pre code.kd {
      color: #069;
      font-weight: bold
    }

    #sbo-rt-content pre code.kn {
      color: #069;
      font-weight: bold
    }

    #sbo-rt-content pre code.kp {
      color: #069
    }

    #sbo-rt-content pre code.kr {
      color: #069;
      font-weight: bold
    }

    #sbo-rt-content pre code.kt {
      color: #078;
      font-weight: bold
    }

    #sbo-rt-content pre code.m {
      color: #F60
    }

    #sbo-rt-content pre code.s {
      color: #C30
    }

    #sbo-rt-content pre code.na {
      color: #309
    }

    #sbo-rt-content pre code.nb {
      color: #366
    }

    #sbo-rt-content pre code.nc {
      color: #0A8;
      font-weight: bold
    }

    #sbo-rt-content pre code.no {
      color: #360
    }

    #sbo-rt-content pre code.nd {
      color: #99F
    }

    #sbo-rt-content pre code.ni {
      color: #999;
      font-weight: bold
    }

    #sbo-rt-content pre code.ne {
      color: #C00;
      font-weight: bold
    }

    #sbo-rt-content pre code.nf {
      color: #C0F
    }

    #sbo-rt-content pre code.nl {
      color: #99F
    }

    #sbo-rt-content pre code.nn {
      color: #0CF;
      font-weight: bold
    }

    #sbo-rt-content pre code.nt {
      color: #309;
      font-weight: bold
    }

    #sbo-rt-content pre code.nv {
      color: #033
    }

    #sbo-rt-content pre code.ow {
      color: #000;
      font-weight: bold
    }

    #sbo-rt-content pre code.w {
      color: #bbb
    }

    #sbo-rt-content pre code.mf {
      color: #F60
    }

    #sbo-rt-content pre code.mh {
      color: #F60
    }

    #sbo-rt-content pre code.mi {
      color: #F60
    }

    #sbo-rt-content pre code.mo {
      color: #F60
    }

    #sbo-rt-content pre code.sb {
      color: #C30
    }

    #sbo-rt-content pre code.sc {
      color: #C30
    }

    #sbo-rt-content pre code.sd {
      color: #C30;
      font-style: italic
    }

    #sbo-rt-content pre code.s2 {
      color: #C30
    }

    #sbo-rt-content pre code.se {
      color: #C30;
      font-weight: bold
    }

    #sbo-rt-content pre code.sh {
      color: #C30
    }

    #sbo-rt-content pre code.si {
      color: #A00
    }

    #sbo-rt-content pre code.sx {
      color: #C30
    }

    #sbo-rt-content pre code.sr {
      color: #3AA
    }

    #sbo-rt-content pre code.s1 {
      color: #C30
    }

    #sbo-rt-content pre code.ss {
      color: #A60
    }

    #sbo-rt-content pre code.bp {
      color: #366
    }

    #sbo-rt-content pre code.vc {
      color: #033
    }

    #sbo-rt-content pre code.vg {
      color: #033
    }

    #sbo-rt-content pre code.vi {
      color: #033
    }

    #sbo-rt-content pre code.il {
      color: #F60
    }

    #sbo-rt-content pre code.g {
      color: #050
    }

    #sbo-rt-content pre code.l {
      color: #C60
    }

    #sbo-rt-content pre code.l {
      color: #F90
    }

    #sbo-rt-content pre code.n {
      color: #008
    }

    #sbo-rt-content pre code.nx {
      color: #008
    }

    #sbo-rt-content pre code.py {
      color: #96F
    }

    #sbo-rt-content pre code.p {
      color: #000
    }

    #sbo-rt-content pre code.x {
      color: #F06
    }

    #sbo-rt-content div.blockquote_sampler_toc {
      width: 95%;
      margin: 5px 5px 5px 10px !important
    }

    #sbo-rt-content div {
      font-family: serif;
      text-align: left
    }

    #sbo-rt-content .gray-background,
    #sbo-rt-content .reverse-video {
      background: #2E2E2E;
      color: #FFF
    }

    #sbo-rt-content .light-gray-background {
      background: #A0A0A0
    }

    #sbo-rt-content .preserve-whitespace {
      white-space: pre-wrap
    }

    #sbo-rt-content span.gray {
      color: #4C4C4C
    }

    #sbo-rt-content .width-10 {
      width: 10vw !important
    }

    #sbo-rt-content .width-20 {
      width: 20vw !important
    }

    #sbo-rt-content .width-30 {
      width: 30vw !important
    }

    #sbo-rt-content .width-40 {
      width: 40vw !important
    }

    #sbo-rt-content .width-50 {
      width: 50vw !important
    }

    #sbo-rt-content .width-60 {
      width: 60vw !important
    }

    #sbo-rt-content .width-70 {
      width: 70vw !important
    }

    #sbo-rt-content .width-80 {
      width: 80vw !important
    }

    #sbo-rt-content .width-90 {
      width: 90vw !important
    }

    #sbo-rt-content .width-full,
    #sbo-rt-content .width-100 {
      width: 100vw !important
    }

    #sbo-rt-content div[data-type="equation"].fifty-percent img {
      width: 50%
    }
  </style>
  <style type="text/css" id="font-styles">
    #sbo-rt-content,
    #sbo-rt-content p,
    #sbo-rt-content div {
      font-size: &lt;
      %=font_size %&gt;
      !important;
    }
  </style>
  <style type="text/css" id="font-family">
    #sbo-rt-content,
    #sbo-rt-content p,
    #sbo-rt-content div {
      font-family: &lt;
      %=font_family %&gt;
      !important;
    }
  </style>
  <style type="text/css" id="column-width">
    #sbo-rt-content {
      max-width: &lt;
      %=column_width %&gt;
      % !important;
      margin: 0 auto !important;
    }
  </style>

  <style type="text/css">
    body {
      background-color: #fbfbfb !important;
      margin: 1em;
    }

    #sbo-rt-content * {
      text-indent: 0pt !important;
    }

    #sbo-rt-content .bq {
      margin-right: 1em !important;
    }

    #sbo-rt-content * {
      word-wrap: break-word !important;
      word-break: break-word !important;
    }

    #sbo-rt-content table,
    #sbo-rt-content pre {
      overflow-x: unset !important;
      overflow: unset !important;
      overflow-y: unset !important;
      white-space: pre-wrap !important;
    }
  </style>
</head>

<body>
  <div id="sbo-rt-content">
    <section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 3. Classification">
      <div class="chapter" id="classification_chapter">
        <h1><span class="label">Chapter 3. </span>Classification</h1>


        <p>In <a data-type="xref" href="ch01.xhtml#landscape_chapter">Chapter 1</a> we mentioned that the most common
          supervised learning tasks are regression (predicting values) and classification (predicting classes). In <a
            data-type="xref" href="ch02.xhtml#project_chapter">Chapter 2</a> we explored a regression task, predicting
          housing values, using various algorithms such as Linear Regression, Decision Trees, and Random Forests (which
          will be explained in further detail in later chapters). Now we will turn our attention to classification
          systems.</p>






        <section data-type="sect1" data-pdf-bookmark="MNIST">
          <div class="sect1" id="idm139656383701792">
            <h1>MNIST</h1>

            <p>In this <a data-type="indexterm" data-primary="classifiers" data-secondary="MNIST dataset"
                id="c3mnistd" /><a data-type="indexterm" data-primary="MNIST dataset" id="mnistd3" />chapter, we will be
              using the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school
              students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This
              set has been studied so much that it is often called the “Hello World” of Machine Learning: whenever
              people come up with a new classification algorithm, they are curious to see how it will perform on MNIST.
              Whenever someone learns Machine Learning, sooner or later they tackle MNIST.</p>

            <p>Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them. The
              following code fetches the MNIST dataset:<sup><a data-type="noteref" id="idm139656383696416-marker"
                  href="ch03.xhtml#idm139656383696416">1</a></sup></p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.datasets</code> <code class="kn">import</code> <code class="n">fetch_openml</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">mnist</code> <code class="o">=</code> <code class="n">fetch_openml</code><code class="p">(</code><code class="s">'mnist_784'</code><code class="p">,</code> <code class="n">version</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">mnist</code><code class="o">.</code><code class="n">keys</code><code class="p">()</code>
<code class="go">dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details',</code>
<code class="go">           'categories', 'url'])</code></pre>

            <p>Datasets loaded by Scikit-Learn generally have a similar dictionary structure including:</p>

            <ul>
              <li>
                <p>A <code>DESCR</code> key describing the dataset</p>
              </li>
              <li>
                <p>A <code>data</code> key containing an array with one row per instance and one column per feature</p>
              </li>
              <li>
                <p>A <code>target</code> key containing an array with the labels</p>
              </li>
            </ul>

            <p>Let’s look at these arrays:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="p">,</code> <code class="n">y</code> <code class="o">=</code> <code class="n">mnist</code><code class="p">[</code><code class="s">"data"</code><code class="p">],</code> <code class="n">mnist</code><code class="p">[</code><code class="s">"target"</code><code class="p">]</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">shape</code>
<code class="go">(70000, 784)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y</code><code class="o">.</code><code class="n">shape</code>
<code class="go">(70000,)</code></pre>

            <p>There are 70,000 images, and each image has 784 features. This is because each image is 28×28 pixels, and
              each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black). Let’s take a peek at
              one digit from the dataset. All you need to do is grab an instance’s feature vector, reshape it to a 28×28
              array, and display it using Matplotlib’s <code>imshow()</code> function:</p>

            <pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">matplotlib</code> <code class="kn">as</code> <code class="nn">mpl</code>
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>

<code class="n">some_digit</code> <code class="o">=</code> <code class="n">X</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
<code class="n">some_digit_image</code> <code class="o">=</code> <code class="n">some_digit</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="mi">28</code><code class="p">,</code> <code class="mi">28</code><code class="p">)</code>

<code class="n">plt</code><code class="o">.</code><code class="n">imshow</code><code class="p">(</code><code class="n">some_digit_image</code><code class="p">,</code> <code class="n">cmap</code> <code class="o">=</code> <code class="n">mpl</code><code class="o">.</code><code class="n">cm</code><code class="o">.</code><code class="n">binary</code><code class="p">,</code> <code class="n">interpolation</code><code class="o">=</code><code class="s2">"nearest"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">axis</code><code class="p">(</code><code class="s2">"off"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

            <figure class="smallertwenty">
              <div class="figure">
                <img src="mlst_03in01.png" alt="mlst 03in01" width="731" height="730" />
                <h6 />
              </div>
            </figure>

            <p>This looks like a 5, and indeed that’s what the label tells us:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
<code class="go">'5'</code></pre>

            <p>Note that the label is a string. We prefer numbers, so let’s cast <code>y</code> to integers:</p>

            <pre data-type="programlisting"
              data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y</code> <code class="o">=</code> <code class="n">y</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">uint8</code><code class="p">)</code></pre>

            <p><a data-type="xref" href="#more_digits_plot">Figure 3-1</a> shows a few more images from the MNIST
              dataset to give you a feel for the complexity of the classification task.</p>

            <figure class="smallerseventy">
              <div id="more_digits_plot" class="figure">
                <img src="mlst_0301.png" alt="mlst 0301" width="2456" height="2474" />
                <h6><span class="label">Figure 3-1. </span>A few digits from the MNIST dataset</h6>
              </div>
            </figure>

            <p>But wait! You should always create a <a data-type="indexterm" data-primary="test set"
                id="idm139656383610368" />test set and set it aside before inspecting the data closely. The MNIST
              dataset is actually already split into a training set (the first 60,000 images) and a test set (the last
              10,000 images):</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">X</code><code class="p">[:</code><code class="mi">60000</code><code class="p">],</code> <code class="n">X</code><code class="p">[</code><code class="mi">60000</code><code class="p">:],</code> <code class="n">y</code><code class="p">[:</code><code class="mi">60000</code><code class="p">],</code> <code class="n">y</code><code class="p">[</code><code class="mi">60000</code><code class="p">:]</code></pre>

            <p>The training set is already shuffled for us, which is good as this guarantees that all cross-validation
              <a data-type="indexterm" data-primary="folds" id="idm139656383423520" />folds will be similar (you don’t
              want one fold to be missing some digits). Moreover, some learning algorithms are sensitive to the order of
              the training instances, and they perform poorly if they get many similar instances in a row. Shuffling the
              dataset ensures that this won’t <a data-type="indexterm" data-primary="classifiers"
                data-secondary="MNIST dataset" data-startref="c3mnistd" id="idm139656383422480" /><a
                data-type="indexterm" data-primary="MNIST dataset" data-startref="mnistd3"
                id="idm139656383421328" />happen.<sup><a data-type="noteref" id="idm139656383480240-marker"
                  href="ch03.xhtml#idm139656383480240">2</a></sup></p>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Training a Binary Classifier">
          <div class="sect1" id="idm139656383700880">
            <h1>Training a Binary Classifier</h1>

            <p>Let’s <a data-type="indexterm" data-primary="classifiers" data-secondary="binary"
                id="idm139656383478320" /><a data-type="indexterm" data-primary="binary classifiers"
                id="idm139656383477312" />simplify the problem for now and only try to identify one digit—for example,
              the number 5. This “5-detector” will be an example of a <em>binary classifier</em>, capable of
              distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this
              classification task:</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="n">y_train_5</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_train</code> <code class="o">==</code> <code class="mi">5</code><code class="p">)</code>  <code class="c1"># True for all 5s, False for all other digits.</code>
<code class="n">y_test_5</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_test</code> <code class="o">==</code> <code class="mi">5</code><code class="p">)</code></pre>

            <p>Okay, now let’s pick a classifier and train it. A good place to start is with <a data-type="indexterm"
                data-primary="Stochastic Gradient Descent (SGD) classifier" id="idm139656383466016" />a <em>Stochastic
                Gradient Descent</em> (SGD) classifier, using <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="SGDClassifier" id="idm139656383464880" />Scikit-Learn’s <code>SGDClassifier</code>
              class. This classifier has the advantage of being capable of handling very large datasets efficiently.
              This is in part because SGD deals with training instances independently, one at a time (which also makes
              SGD well suited for <em>online learning</em>), as we will see later. Let’s create an
              <code>SGDClassifier</code> <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.linear_model.SGDClassifier" id="idm139656383295776" />and train it on the whole
              training set:</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">SGDClassifier</code>

<code class="n">sgd_clf</code> <code class="o">=</code> <code class="n">SGDClassifier</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">sgd_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">)</code></pre>
            <div data-type="tip">
              <h6>Tip</h6>
              <p>The <code>SGDClassifier</code> relies on randomness during training (hence the name “stochastic”). If
                you want reproducible results, you should set the <code>random_state</code> parameter.</p>
            </div>

            <p>Now you can use it to detect images of the number 5:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([ True])</code></pre>

            <p>The classifier guesses that this image represents a 5 (<code>True</code>). Looks like it guessed right in
              this particular case! Now, let’s evaluate this model’s performance.</p>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Performance Measures">
          <div class="sect1" id="idm139656383225520">
            <h1>Performance Measures</h1>

            <p>Evaluating <a data-type="indexterm" data-primary="classifiers" data-secondary="performance measures"
                id="c3pm" />a classifier is often significantly trickier than evaluating a regressor, so we will spend a
              large part of this chapter on this topic. There are many performance measures available, so grab another
              coffee and get ready to learn many new concepts and acronyms!</p>








            <section data-type="sect2" data-pdf-bookmark="Measuring Accuracy Using Cross-Validation">
              <div class="sect2" id="idm139656383222272">
                <h2>Measuring Accuracy Using Cross-Validation</h2>

                <p>A <a data-type="indexterm" data-primary="performance measures" data-secondary="cross-validation"
                    id="pm3cv" /><a data-type="indexterm" data-primary="cross-validation" id="cv3" /><a
                    data-type="indexterm" data-primary="accuracy" id="a3ipm" /><a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.model_selection.cross_val_score()"
                    id="sklmscvsch3" />good way to evaluate a model is to use cross-validation, just as you did in <a
                    data-type="xref" href="ch02.xhtml#project_chapter">Chapter 2</a>.</p>
                <aside data-type="sidebar" epub:type="sidebar">
                  <div class="sidebar" id="idm139656383247856">
                    <h5>Implementing Cross-Validation</h5>
                    <p>Occasionally you will need more control over the cross-validation process than what Scikit-Learn
                      provides off-the-shelf. In these cases, you can implement cross-validation yourself; it is
                      actually fairly straightforward. The following code does roughly the same thing as Scikit-Learn’s
                      <code>cross_val_score()</code> function, and prints the <a data-type="indexterm"
                        data-primary="folds" id="fold16" /><a data-type="indexterm" data-primary="Scikit-Learn"
                        data-secondary="sklearn.model_selection.StratifiedKFold" id="idm139656383244864" /><a
                        data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.base.clone()"
                        id="idm139656383243952" />same result:</p>

                    <pre data-type="programlisting"
                      data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">StratifiedKFold</code>
<code class="kn">from</code> <code class="nn">sklearn.base</code> <code class="kn">import</code> <code class="n">clone</code>

<code class="n">skfolds</code> <code class="o">=</code> <code class="n">StratifiedKFold</code><code class="p">(</code><code class="n">n_splits</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>

<code class="k">for</code> <code class="n">train_index</code><code class="p">,</code> <code class="n">test_index</code> <code class="ow">in</code> <code class="n">skfolds</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">):</code>
    <code class="n">clone_clf</code> <code class="o">=</code> <code class="n">clone</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">)</code>
    <code class="n">X_train_folds</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[</code><code class="n">train_index</code><code class="p">]</code>
    <code class="n">y_train_folds</code> <code class="o">=</code> <code class="n">y_train_5</code><code class="p">[</code><code class="n">train_index</code><code class="p">]</code>
    <code class="n">X_test_fold</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[</code><code class="n">test_index</code><code class="p">]</code>
    <code class="n">y_test_fold</code> <code class="o">=</code> <code class="n">y_train_5</code><code class="p">[</code><code class="n">test_index</code><code class="p">]</code>

    <code class="n">clone_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_folds</code><code class="p">,</code> <code class="n">y_train_folds</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">clone_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_fold</code><code class="p">)</code>
    <code class="n">n_correct</code> <code class="o">=</code> <code class="nb">sum</code><code class="p">(</code><code class="n">y_pred</code> <code class="o">==</code> <code class="n">y_test_fold</code><code class="p">)</code>
    <code class="k">print</code><code class="p">(</code><code class="n">n_correct</code> <code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">y_pred</code><code class="p">))</code>  <code class="c1"># prints 0.9502, 0.96565 and 0.96495</code></pre>

                    <p>The <code>StratifiedKFold</code> class performs <a data-type="indexterm"
                        data-primary="stratified sampling" id="idm139656383240752" />stratified sampling (as explained
                      in <a data-type="xref" href="ch02.xhtml#project_chapter">Chapter 2</a>) to produce folds that
                      contain a representative ratio of each class. At each iteration the code creates a clone of the
                      classifier, trains that clone on the training folds, and makes predictions on the test fold. Then
                      it counts the number of correct predictions and outputs the ratio of correct predictions.</p>
                  </div>
                </aside>

                <p>Let’s use the <code>cross_val_score()</code> function to evaluate your <code>SGDClassifier</code>
                  model using <a data-type="indexterm" data-primary="K-fold cross-validation"
                    id="idm139656383178528" />K-fold cross-validation, with three folds. Remember that K-fold
                  cross-validation means splitting the training set into K-folds (in this case, three), then making
                  predictions and evaluating them on each fold using a model trained on the remaining folds (see <a
                    data-type="xref" href="ch02.xhtml#project_chapter">Chapter 2</a>):</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">cross_val_score</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cross_val_score</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">scoring</code><code class="o">=</code><code class="s">"accuracy"</code><code class="p">)</code>
<code class="go">array([0.96355, 0.93795, 0.95615])</code></pre>

                <p>Wow! Above 93% <em>accuracy</em> (ratio of correct predictions) on all cross-validation folds? <a
                    data-type="indexterm" data-primary="folds" data-startref="fold16" id="idm139656383161200" />This
                  looks amazing, doesn’t it? Well, before you get too excited, let’s look at a very dumb classifier that
                  just classifies<a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.base.BaseEstimator" id="idm139656383160160" /> every single image in the
                  “not-5” class:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.base</code> <code class="kn">import</code> <code class="n">BaseEstimator</code>

<code class="k">class</code> <code class="nc">Never5Classifier</code><code class="p">(</code><code class="n">BaseEstimator</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">fit</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
        <code class="k">pass</code>
    <code class="k">def</code> <code class="nf">predict</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="k">return</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">((</code><code class="nb">len</code><code class="p">(</code><code class="n">X</code><code class="p">),</code> <code class="mi">1</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="nb">bool</code><code class="p">)</code></pre>

                <p>Can you guess this model’s accuracy? Let’s find out:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">never_5_clf</code> <code class="o">=</code> <code class="n">Never5Classifier</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cross_val_score</code><code class="p">(</code><code class="n">never_5_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">scoring</code><code class="o">=</code><code class="s">"accuracy"</code><code class="p">)</code>
<code class="go">array([0.91125, 0.90855, 0.90915])</code></pre>

                <p>That’s right, it has over 90% accuracy! This is simply because only about 10% of the images are 5s,
                  so if you always guess that an image is <em>not</em> a 5, you will be right about 90% of the time.
                  Beats Nostradamus.</p>

                <p>This demonstrates why accuracy is generally not the preferred performance measure for classifiers,
                  especially when you are <a data-type="indexterm" data-primary="performance measures"
                    data-secondary="cross-validation" data-startref="pm3cv" id="idm139656383103728" /><a
                    data-type="indexterm" data-primary="cross-validation" data-startref="cv3"
                    id="idm139656383102576" /><a data-type="indexterm" data-primary="accuracy" data-startref="a3ipm"
                    id="idm139656383101632" />dealing <a data-type="indexterm" data-primary="skewed datasets"
                    id="idm139656382863200" />with <em>skewed datasets</em> (i.e., when some classes are much more
                  frequent than others).</p>
              </div>
            </section>













            <section data-type="sect2" data-pdf-bookmark="Confusion Matrix">
              <div class="sect2" id="idm139656383221680">
                <h2>Confusion Matrix</h2>

                <p>A <a data-type="indexterm" data-primary="performance measures" data-secondary="confusion matrix"
                    id="pm3cm" /><a data-type="indexterm" data-primary="confusion matrix" id="cm3" />much better way to
                  evaluate the performance of a classifier is to look at the <em>confusion matrix</em>. The general idea
                  is to count the number of times instances of class A are classified as class B. For example, to know
                  the number of times the classifier confused images of 5s with 3s, you would look in the 5<sup>th</sup>
                  row and 3<sup>rd</sup> column of the confusion matrix.</p>

                <p>To compute the confusion matrix, you first need to have a set of predictions, <a
                    data-type="indexterm" data-primary="predictions" id="pred3" />so they can be compared to the actual
                  targets. You could make predictions on the test set, but let’s keep it untouched for now (remember
                  that you want to use the test set only at the very end of your project, once you have a classifier
                  that you are ready to launch). Instead, you can use the <code>cross_val_predict()</code> <a
                    data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.model_selection.cross_val_predict()" id="idm139656382854224" />function:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">cross_val_predict</code>

<code class="n">y_train_pred</code> <code class="o">=</code> <code class="n">cross_val_predict</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code></pre>

                <p>Just like the <code>cross_val_score()</code> <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.model_selection.cross_val_score()" data-startref="sklmscvsch3"
                    id="idm139656382827488" />function, <code>cross_val_predict()</code> performs K-fold
                  cross-validation, but instead of returning the evaluation scores, it returns the predictions made on
                  each test fold. This means that you get a clean prediction for each instance in the training set
                  (“clean” meaning that the prediction is made by a model that never saw the data during training).</p>

                <p>Now you are ready to get the <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.confusion_matrix()" id="idm139656382824912" />confusion matrix using
                  the <code>confusion_matrix()</code> function. Just pass it the target classes (<code>y_train_5</code>)
                  and the predicted classes (<code>y_train_pred</code>):</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">confusion_matrix</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred</code><code class="p">)</code>
<code class="go">array([[53057,  1522],</code>
<code class="go">       [ 1325,  4096]])</code></pre>

                <p>Each row in a confusion matrix represents an <em>actual class</em>, while each column represents a
                  <em>predicted class</em>. <a data-type="indexterm" data-primary="actual class"
                    id="idm139656382818128" /><a data-type="indexterm" data-primary="predicted class"
                    id="idm139656382794080" />The first row of this matrix considers non-5 images (the <em>negative
                    class</em>): 53,057 of them were correctly classified as non-5s (they are called <em>true
                    negatives</em>), while the remaining 1,522 were wrongly classified as 5s (<em>false positives</em>).
                  The second row considers the images of 5s (the <em>positive class</em>): 1,325 were wrongly classified
                  as non-5s (<em>false negatives</em>), while the remaining 4,096 were correctly classified as 5s
                  (<em>true positives</em>). A perfect classifier would have only true positives and true negatives, so
                  its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):
                </p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y_train_perfect_predictions</code> <code class="o">=</code> <code class="n">y_train_5</code>  <code class="c"># pretend we reached perfection</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_perfect_predictions</code><code class="p">)</code>
<code class="go">array([[54579,     0],</code>
<code class="go">       [    0,  5421]])</code></pre>

                <p>The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise
                  metric. An interesting one to look at is the accuracy of the positive predictions; this is called <a
                    data-type="indexterm" data-primary="classifiers" data-secondary="precision of"
                    id="idm139656382813552" /><a data-type="indexterm" data-primary="precision"
                    id="idm139656382812672" />the <em>precision</em> of the classifier (<a data-type="xref"
                    href="#equation_three_one">Equation 3-1</a>).</p>
                <div data-type="equation" id="equation_three_one">
                  <h5><span class="label">Equation 3-1. </span>Precision</h5>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                      <mtext>precision</mtext>
                      <mo>=</mo>
                      <mfrac>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                        </mrow>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                          <mo>+</mo>
                          <mi>F</mi>
                          <mi>P</mi>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </math>
                </div>

                <p>TP is the number of true positives, and FP is the number of false positives.</p>

                <p>A trivial way to have perfect precision is to make one single positive prediction and ensure it is
                  correct (precision = 1/1 = 100%). This would not be very useful since the classifier would ignore all
                  but one positive instance. So precision is typically used along with another metric named
                  <em>recall</em>, <a data-type="indexterm" data-primary="recall" id="idm139656382769504" /><a
                    data-type="indexterm" data-primary="sensitivity" id="idm139656382768768" /><a data-type="indexterm"
                    data-primary="true positive rate (TPR)" id="idm139656382768096" />also called <em>sensitivity</em>
                  or <em>true positive rate</em> (<em>TPR</em>): this is the ratio of positive instances that are
                  correctly detected by the classifier (<a data-type="xref" href="#equation_three_two">Equation
                    3-2</a>).</p>
                <div data-type="equation" id="equation_three_two">
                  <h5><span class="label">Equation 3-2. </span>Recall</h5>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                      <mtext>recall</mtext>
                      <mo>=</mo>
                      <mfrac>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                        </mrow>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                          <mo>+</mo>
                          <mi>F</mi>
                          <mi>N</mi>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </math>
                </div>

                <p>FN is of course the number of false negatives.</p>

                <p>If you are confused about the confusion matrix, <a data-type="xref"
                    href="#confusion_matrix_diagram">Figure 3-2</a> may <a data-type="indexterm"
                    data-primary="performance measures" data-secondary="confusion matrix" data-startref="pm3cm"
                    id="idm139656382754912" /><a data-type="indexterm" data-primary="confusion matrix"
                    data-startref="cm3" id="idm139656382753664" /><a data-type="indexterm" data-primary="predictions"
                    data-startref="pred3" id="idm139656382752720" />help.</p>

                <figure>
                  <div id="confusion_matrix_diagram" class="figure">
                    <img src="mlst_0302.png" alt="mlst 0302" width="2283" height="1084" />
                    <h6><span class="label">Figure 3-2. </span>An illustrated confusion matrix</h6>
                  </div>
                </figure>
              </div>
            </section>













            <section data-type="sect2" data-pdf-bookmark="Precision and Recall">
              <div class="sect2" id="idm139656382861360">
                <h2>Precision and Recall</h2>

                <p>Scikit-Learn <a data-type="indexterm" data-primary="performance measures"
                    data-secondary="precision and recall" id="pm3par" /><a data-type="indexterm"
                    data-primary="precision and recall" id="par3" />provides several functions to compute classifier
                  metrics, including <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.precision_score()" id="idm139656382940112" /> <a
                    data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.metrics.recall_score()"
                    id="idm139656382938976" />precision and recall:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">precision_score</code><code class="p">,</code> <code class="n">recall_score</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">precision_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred</code><code class="p">)</code> <code class="c"># == 4096 / (4096 + 1522)</code>
<code class="go">0.7290850836596654</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">recall_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred</code><code class="p">)</code> <code class="c"># == 4096 / (4096 + 1325)</code>
<code class="go">0.7555801512636044</code></pre>

                <p>Now your 5-detector does not look as shiny as it did when you looked at its accuracy. When it claims
                  an image represents a 5, it is correct only 72.9% of the time. Moreover, it only detects 75.6% of the
                  5s.</p>

                <p>It is often convenient to combine precision and recall into a single metric called the
                  <em>F<sub>1</sub> score</em>, in particular if you need a simple way to compare two classifiers. The
                  <a data-type="indexterm" data-primary="precision and recall" data-secondary="F-1 score"
                    id="par3f1s" /><a data-type="indexterm" data-primary="F-1 score" id="f1s3" />F<sub>1</sub> score is
                  <a data-type="indexterm" data-primary="harmonic mean" id="idm139656382914704" />the <em>harmonic
                    mean</em> of precision and recall (<a data-type="xref" href="#equation_three_three">Equation
                    3-3</a>). Whereas the regular mean treats all values equally, the harmonic mean gives much more
                  weight to low values. As a result, the classifier will only get a high F<sub>1</sub> score if both
                  recall and precision are high.</p>
                <div data-type="equation" id="equation_three_three">
                  <h5><span class="label">Equation 3-3. </span>F<sub>1</sub></h5>
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                      <msub>
                        <mi>F</mi>
                        <mn>1</mn>
                      </msub>
                      <mo>=</mo>
                      <mfrac>
                        <mn>2</mn>
                        <mrow>
                          <mfrac>
                            <mn>1</mn>
                            <mtext>precision</mtext>
                          </mfrac>
                          <mo>+</mo>
                          <mfrac>
                            <mn>1</mn>
                            <mtext>recall</mtext>
                          </mfrac>
                        </mrow>
                      </mfrac>
                      <mo>=</mo>
                      <mn>2</mn>
                      <mo>×</mo>
                      <mfrac>
                        <mrow>
                          <mtext>precision</mtext>
                          <mspace width="0.166667em" />
                          <mo>×</mo>
                          <mspace width="0.166667em" />
                          <mtext>recall</mtext>
                        </mrow>
                        <mrow>
                          <mtext>precision</mtext>
                          <mspace width="0.166667em" />
                          <mo>+</mo>
                          <mspace width="0.166667em" />
                          <mtext>recall</mtext>
                        </mrow>
                      </mfrac>
                      <mo>=</mo>
                      <mfrac>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                        </mrow>
                        <mrow>
                          <mi>T</mi>
                          <mi>P</mi>
                          <mo>+</mo>
                          <mfrac>
                            <mrow>
                              <mi>F</mi>
                              <mi>N</mi>
                              <mo>+</mo>
                              <mi>F</mi>
                              <mi>P</mi>
                            </mrow>
                            <mn>2</mn>
                          </mfrac>
                        </mrow>
                      </mfrac>
                    </mrow>
                  </math>
                </div>

                <p>To compute <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.f1_score()" id="idm139656382705616" />the F<sub>1</sub> score,
                  simply call the <code>f1_score()</code> function:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">f1_score</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">f1_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred</code><code class="p">)</code>
<code class="go">0.7420962043663375</code></pre>

                <p>The F<sub>1</sub> score favors classifiers that have similar precision and recall. This is not always
                  what you want: in some contexts you mostly care about precision, and in other contexts you really care
                  about recall. For example, if you trained a classifier to detect videos that are safe for kids, you
                  would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones
                  (high precision), rather than a classifier that has a much higher recall but lets a few really bad
                  videos show up in your product (in such cases, you may even want to add a human pipeline to check the
                  classifier’s video selection). On the other hand, suppose you train a classifier to detect shoplifters
                  on surveillance images: it is probably fine if your classifier has only 30% precision as long as it
                  has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will
                  get caught).</p>

                <p>Unfortunately, you can’t have it both ways: increasing precision reduces recall, and vice versa. This
                  <a data-type="indexterm" data-primary="precision and recall" data-secondary="F-1 score"
                    data-startref="par3f1s" id="idm139656382675680" /><a data-type="indexterm" data-primary="F-1 score"
                    data-startref="f1s3" id="idm139656382674496" />is called the <em>precision/recall tradeoff</em>.</p>
              </div>
            </section>













            <section data-type="sect2" data-pdf-bookmark="Precision/Recall Tradeoff">
              <div class="sect2" id="idm139656382749072">
                <h2>Precision/Recall Tradeoff</h2>

                <p>To <a data-type="indexterm" data-primary="precision and recall"
                    data-secondary="precision/recall tradeoff" id="par3prt" />understand this tradeoff, let’s look at
                  how the<a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="SGDClassifier"
                    id="sl3sgdc" /> <code>SGDClassifier</code> makes its classification decisions. For each instance, it
                  computes a score based on a <em>decision function</em>, <a data-type="indexterm"
                    data-primary="decision function" id="idm139656382592880" />and if that score is greater than a
                  threshold, it assigns the instance to the positive class, or else it assigns it to the negative class.
                  <a data-type="xref" href="#decision_threshold_diagram">Figure 3-3</a> shows a few digits positioned
                  from the lowest score on the left to the highest score on the right. Suppose the <em>decision
                    threshold</em> <a data-type="indexterm" data-primary="decision threshold"
                    id="idm139656382590576" />is positioned at the central arrow (between the two 5s): you will find 4
                  true positives (actual 5s) on the right of that threshold, and one false positive (actually a 6).
                  Therefore, with that threshold, the precision is 80% (4 out of 5). But out of 6 actual 5s, the
                  classifier only detects 4, so the recall is 67% (4 out of 6). Now if you raise the threshold (move it
                  to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing
                  precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall
                  down to 50%. Conversely, lowering the threshold increases recall and reduces precision.</p>

                <figure>
                  <div id="decision_threshold_diagram" class="figure">
                    <img src="mlst_0303.png" alt="mlst 0303" width="2445" height="681" />
                    <h6><span class="label">Figure 3-3. </span>Decision threshold and precision/recall tradeoff</h6>
                  </div>
                </figure>

                <p>Scikit-Learn does not let you set the threshold directly, but it does give you access to the decision
                  scores that it uses to make predictions. Instead of calling the classifier’s <code>predict()</code>
                  method, you can call its <code>decision_function()</code> method, which returns a score for each
                  instance, and then make predictions based on those scores using any threshold you want:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y_scores</code> <code class="o">=</code> <code class="n">sgd_clf</code><code class="o">.</code><code class="n">decision_function</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_scores</code>
<code class="go">array([2412.53175101])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">threshold</code> <code class="o">=</code> <code class="mi">0</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_some_digit_pred</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_scores</code> <code class="o">&gt;</code> <code class="n">threshold</code><code class="p">)</code>
<code class="go">array([ True])</code></pre>

                <p>The <code>SGDClassifier</code> uses a threshold equal to 0, so the previous code returns the same
                  result as the <code>predict()</code> method (i.e., <code>True</code>). Let’s raise the threshold:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">threshold</code> <code class="o">=</code> <code class="mi">8000</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_some_digit_pred</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_scores</code> <code class="o">&gt;</code> <code class="n">threshold</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_some_digit_pred</code>
<code class="go">array([ True])</code></pre>

                <p>This confirms that raising the threshold decreases recall. The image actually represents a 5, and the
                  classifier detects it when the threshold is 0, but it misses it when the threshold is <a
                    data-type="indexterm" data-primary="Scikit-Learn" data-secondary="SGDClassifier"
                    data-startref="sl3sgdc" id="idm139656382648384" />increased to 8,000.</p>

                <p>Now how do you decide which threshold to use? For this you will first need to get the scores of all
                  instances in the training set using the <code>cross_val_predict()</code> function again, but this time
                  specifying that you want it to return decision scores <a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.model_selection.cross_val_predict()"
                    id="idm139656382646176" />instead of predictions:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="n">y_scores</code> <code class="o">=</code> <code class="n">cross_val_predict</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code>
                             <code class="n">method</code><code class="o">=</code><code class="s2">"decision_function"</code><code class="p">)</code></pre>

                <p>Now with these scores you can compute precision and recall for all possible thresholds using the
                  <code>precision_recall_curve()</code> <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.precision_recall_curve()" id="idm139656382488560" />function:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">precision_recall_curve</code>

<code class="n">precisions</code><code class="p">,</code> <code class="n">recalls</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> <code class="n">precision_recall_curve</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_scores</code><code class="p">)</code></pre>

                <p>Finally, you can plot precision and recall as functions of the threshold value using Matplotlib (<a
                    data-type="xref" href="#precision_recall_vs_threshold_plot">Figure 3-4</a>):</p>

                <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">plot_precision_recall_vs_threshold</code><code class="p">(</code><code class="n">precisions</code><code class="p">,</code> <code class="n">recalls</code><code class="p">,</code> <code class="n">thresholds</code><code class="p">):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">thresholds</code><code class="p">,</code> <code class="n">precisions</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">],</code> <code class="s2">"b--"</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"Precision"</code><code class="p">)</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">thresholds</code><code class="p">,</code> <code class="n">recalls</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">],</code> <code class="s2">"g-"</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"Recall"</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># highlight the threshold, add the legend, axis label and grid</code>

<code class="n">plot_precision_recall_vs_threshold</code><code class="p">(</code><code class="n">precisions</code><code class="p">,</code> <code class="n">recalls</code><code class="p">,</code> <code class="n">thresholds</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

                <figure>
                  <div id="precision_recall_vs_threshold_plot" class="figure">
                    <img src="mlst_0304.png" alt="mlst 0304" width="2295" height="1092" />
                    <h6><span class="label">Figure 3-4. </span>Precision and recall versus the decision threshold</h6>
                  </div>
                </figure>
                <div data-type="note" epub:type="note">
                  <h6>Note</h6>
                  <p>You may wonder why the precision curve is bumpier than the recall curve in <a data-type="xref"
                      href="#precision_recall_vs_threshold_plot">Figure 3-4</a>. The reason is that precision may
                    sometimes go down when you raise the threshold (although in general it will go up). To understand
                    why, look back at <a data-type="xref" href="#decision_threshold_diagram">Figure 3-3</a> and notice
                    what happens when you start from the central threshold and move it just one digit to the right:
                    precision goes from 4/5 (80%) down to 3/4 (75%). On the other hand, recall can only go down when the
                    threshold is increased, which explains why its curve looks smooth.</p>
                </div>

                <p>Another way to select a good precision/recall tradeoff is to plot precision directly against recall,
                  as shown in <a data-type="xref" href="#precision_vs_recall_plot">Figure 3-5</a> (the same threshold as
                  earlier is highlighed).</p>

                <figure class="smallerseventy">
                  <div id="precision_vs_recall_plot" class="figure">
                    <img src="mlst_0305.png" alt="mlst 0305" width="2304" height="1692" />
                    <h6><span class="label">Figure 3-5. </span>Precision versus recall</h6>
                  </div>
                </figure>

                <p>You can see that precision really starts to fall sharply around 80% recall. You will probably want to
                  select a precision/recall tradeoff just before that drop—for example, at around 60% recall. But of
                  course the choice depends on your project.</p>

                <p>So let’s suppose you decide to aim for 90% precision. You look up the first plot and find that you
                  need to use a threshold of about 8,000. To be more precise you can search for the lowest threshold
                  that gives you at least 90% precision (<code>np.argmax()</code> will give us the first index of the
                  maximum value, which in this case means the first <code>True</code> value):</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="n">threshold_90_precision</code> <code class="o">=</code> <code class="n">thresholds</code><code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">argmax</code><code class="p">(</code><code class="n">precisions</code> <code class="o">&gt;=</code> <code class="mf">0.90</code><code class="p">)]</code> <code class="c1"># == 7813</code></pre>

                <p>To make predictions (on the training set for now), instead of calling the classifier’s
                  <code>predict()</code> method, you can just run this code:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="n">y_train_pred_90</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_scores</code> <code class="o">&gt;=</code> <code class="n">threshold_90_precision</code><code class="p">)</code></pre>

                <p>Let’s check these predictions’ precision and recall:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">precision_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred_90</code><code class="p">)</code>
<code class="go">0.9000380083618396</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">recall_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_train_pred_90</code><code class="p">)</code>
<code class="go">0.4368197749492714</code></pre>

                <p>Great, you have a 90% precision classifier <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.recall_score()" id="idm139656382245664" /><a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.metrics.precision_score()"
                    id="idm139656382244816" />! As you can see, it is fairly easy to create a classifier with virtually
                  any precision you want: just set a high enough threshold, and you’re done. Hmm, not so fast. A
                  high-precision classifier is not very useful if its <a data-type="indexterm"
                    data-primary="performance measures" data-secondary="precision and recall" data-startref="pm3par"
                    id="idm139656382279024" /><a data-type="indexterm" data-primary="precision and recall"
                    data-startref="par3" id="idm139656382277808" /><a data-type="indexterm"
                    data-primary="precision and recall" data-secondary="precision/recall tradeoff"
                    data-startref="par3prt" id="idm139656382276864" />recall is too low!</p>
                <div data-type="tip">
                  <h6>Tip</h6>
                  <p>If someone says “let’s reach 99% precision,” you should ask, “at what recall?”</p>
                </div>
              </div>
            </section>













            <section data-type="sect2" data-pdf-bookmark="The ROC Curve">
              <div class="sect2" id="idm139656382672096">
                <h2>The ROC Curve</h2>

                <p>The<a data-type="indexterm" data-primary="performance measures"
                    data-secondary="ROC (receiver operating characteristic) curve" id="pm3roc" /><a
                    data-type="indexterm" data-primary="ROC (receiver operating characteristic) curve" id="roc3" />
                  <em>receiver operating characteristic</em> (ROC) curve is another common tool used with binary
                  classifiers. It is very similar to the precision/recall curve, but instead of plotting precision
                  versus recall, the ROC curve plots the <em>true positive rate</em> <a data-type="indexterm"
                    data-primary="true positive rate (TPR)" id="idm139656382307056" />(another name for recall) against
                  the <em>false positive rate</em>. <a data-type="indexterm" data-primary="false positive rate (FPR)"
                    id="fpr3" />The FPR is the ratio of negative instances that are incorrectly classified as positive.
                  It is equal to one minus the <em>true negative rate</em>, <a data-type="indexterm"
                    data-primary="true negative rate (TNR)" id="idm139656382304128" />which is the ratio of negative
                  instances that are correctly classified as negative. The TNR is also called <em>specificity</em>. <a
                    data-type="indexterm" data-primary="sensitivity" id="idm139656382302736" /><a data-type="indexterm"
                    data-primary="specificity" id="idm139656382302000" />Hence the ROC curve plots <em>sensitivity</em>
                  (recall) versus <span class="keep-together">1 – <em>specificity</em></span>.</p>

                <p>To plot the ROC curve, <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.roc_curve()" id="sklmrccha3" />you first need to compute the TPR and
                  FPR for various threshold values, using the <code>roc_curve()</code> function:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_curve</code>

<code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">thresholds</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_scores</code><code class="p">)</code></pre>

                <p>Then you can plot the FPR against the TPR using <a data-type="indexterm" data-primary="Matplotlib"
                    id="idm139656382296336" />Matplotlib. This code produces the plot in <a data-type="xref"
                    href="#roc_curve_plot">Figure 3-6</a>:</p>

                <pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">plot_roc_curve</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="n">label</code><code class="p">)</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="s1">'k--'</code><code class="p">)</code> <code class="c1"># dashed diagonal</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Add axis labels and grid</code>

<code class="n">plot_roc_curve</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

                <figure class="smallerseventy">
                  <div id="roc_curve_plot" class="figure">
                    <img src="mlst_0306.png" alt="mlst 0306" width="2310" height="1692" />
                    <h6><span class="label">Figure 3-6. </span>ROC curve</h6>
                  </div>
                </figure>

                <p>Once again there is a tradeoff: the higher the recall (TPR), the more false positives (FPR) the
                  classifier produces. The dotted line represents the ROC curve of a purely random classifier; a good
                  classifier stays as far away from that line as possible (toward the top-left corner).</p>

                <p>One way to compare classifiers is to measure the <em>area under the curve</em> (AUC). <a
                    data-type="indexterm" data-primary="area under the curve (AUC)" id="idm139656382161424" />A perfect
                  classifier will have a <em>ROC AUC</em> equal to 1, whereas a purely random classifier will have a ROC
                  AUC equal to 0.5. Scikit-Learn provides a function <a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.metrics.roc_auc_score()" id="sklmrasch3" />to
                  compute the ROC AUC:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">roc_auc_score</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_scores</code><code class="p">)</code>
<code class="go">0.9611778893101814</code></pre>
                <div data-type="tip">
                  <h6>Tip</h6>
                  <p>Since the ROC curve is so similar to the <a data-type="indexterm"
                      data-primary="precision and recall" data-secondary="precision/recall (PR) curve"
                      id="idm139656382147328" />precision/recall (or PR) curve, you may wonder how to decide which one
                    to use. As a rule of thumb, you should prefer the PR curve whenever the positive class is rare or
                    when you care more about the false positives than the false negatives, and the ROC curve otherwise.
                    For example, looking at the previous ROC curve (and the ROC AUC score), you may think that the
                    classifier is really good. But this is mostly because there are few positives (5s) compared to the
                    negatives (non-5s). In contrast, the PR curve makes it clear that the classifier has room for
                    improvement (the curve could be closer to the top-right corner).</p>
                </div>

                <p>Let’s train a <code>RandomForestClassifier</code> <a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.ensemble.RandomForestClassifier"
                    id="idm139656382068400" />and compare its ROC curve and ROC AUC score to the
                  <code>SGDClassifier</code>. First, you need to get scores for each instance in the training set. But
                  due to the way it works (see <a data-type="xref" href="ch07.xhtml#ensembles_chapter">Chapter 7</a>),
                  the <code>RandomForestClassifier</code> class does not have a <code>decision_function()</code> method.
                  <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.model_selection.cross_val_predict()" id="idm139656382065024" />Instead it
                  has a <code>predict_proba()</code> method. Scikit-Learn classifiers generally have one or the other.
                  The <code>predict_proba()</code> method returns an array containing a row per instance and a column
                  per class, each containing the probability that the given instance belongs to the given class (e.g.,
                  70% chance that the image represents a 5):</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.ensemble</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>

<code class="n">forest_clf</code> <code class="o">=</code> <code class="n">RandomForestClassifier</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">y_probas_forest</code> <code class="o">=</code> <code class="n">cross_val_predict</code><code class="p">(</code><code class="n">forest_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train_5</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code>
                                    <code class="n">method</code><code class="o">=</code><code class="s2">"predict_proba"</code><code class="p">)</code></pre>

                <p>But to plot a ROC curve, you need scores, not probabilities. A simple solution is to use the positive
                  class’s <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.metrics.roc_curve()" data-startref="sklmrccha3"
                    id="idm139656381989216" />probability as the score:</p>

                <pre data-type="programlisting"
                  data-code-language="python"><code class="n">y_scores_forest</code> <code class="o">=</code> <code class="n">y_probas_forest</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">]</code>   <code class="c1"># score = proba of positive class</code>
<code class="n">fpr_forest</code><code class="p">,</code> <code class="n">tpr_forest</code><code class="p">,</code> <code class="n">thresholds_forest</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code><code class="n">y_scores_forest</code><code class="p">)</code></pre>

                <p>Now you are ready to plot the ROC curve. It is useful to plot the first ROC curve as well to see how
                  they compare (<a data-type="xref" href="#roc_curve_comparison_plot">Figure 3-7</a>):</p>

                <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">fpr</code><code class="p">,</code> <code class="n">tpr</code><code class="p">,</code> <code class="s2">"b:"</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"SGD"</code><code class="p">)</code>
<code class="n">plot_roc_curve</code><code class="p">(</code><code class="n">fpr_forest</code><code class="p">,</code> <code class="n">tpr_forest</code><code class="p">,</code> <code class="s2">"Random Forest"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s2">"lower right"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

                <figure class="smallerseventy">
                  <div id="roc_curve_comparison_plot" class="figure">
                    <img src="mlst_0307.png" alt="mlst 0307" width="2310" height="1692" />
                    <h6><span class="label">Figure 3-7. </span>Comparing ROC curves</h6>
                  </div>
                </figure>

                <p>As <a data-type="indexterm" data-primary="false positive rate (FPR)" data-startref="fpr3"
                    id="idm139656381926368" />you can see in <a data-type="xref"
                    href="#roc_curve_comparison_plot">Figure 3-7</a>, the <code>RandomForestClassifier</code>’s ROC
                  curve looks much better than the <code>SGDClassifier</code>’s: it comes much closer to the top-left
                  corner. As a result, its ROC AUC score is also significantly <a data-type="indexterm"
                    data-primary="Scikit-Learn" data-secondary="sklearn.metrics.roc_auc_score()"
                    data-startref="sklmrasch3" id="idm139656381923504" />better:</p>

                <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_train_5</code><code class="p">,</code> <code class="n">y_scores_forest</code><code class="p">)</code>
<code class="go">0.9983436731328145</code></pre>

                <p>Try measuring the precision and recall scores: you should find 99.0% precision and 86.6% recall. Not
                  too bad!</p>

                <p>Hopefully you now know how to train binary classifiers, choose the appropriate metric for your task,
                  evaluate your classifiers using cross-validation, select the precision/recall tradeoff that fits your
                  needs, and compare various models using ROC curves and ROC AUC scores. Now let’s try to detect more
                  than <a data-type="indexterm" data-primary="performance measures"
                    data-secondary="ROC (receiver operating characteristic) curve" data-startref="pm3roc"
                    id="idm139656381914880" /><a data-type="indexterm"
                    data-primary="ROC (receiver operating characteristic) curve" data-startref="roc3"
                    id="idm139656381913792" /><a data-type="indexterm" data-primary="classifiers"
                    data-secondary="performance measures" data-startref="c3pm" id="idm139656381912880" />just the 5s.
                </p>
              </div>
            </section>





          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Multiclass Classification">
          <div class="sect1" id="idm139656382273392">
            <h1>Multiclass Classification</h1>

            <p>Whereas <a data-type="indexterm" data-primary="classifiers" data-secondary="multiclass" id="c3m" /><a
                data-type="indexterm" data-primary="multiclass classifiers" id="mcc3" />binary classifiers distinguish
              between two classes, <em>multiclass classifiers</em> (also called <em>multinomial classifiers</em>) can
              distinguish between more than two classes.</p>

            <p>Some algorithms (such as <a data-type="indexterm" data-primary="Random Forests"
                id="idm139656381903824" />Random Forest classifiers or <a data-type="indexterm"
                data-primary="naive Bayes classifiers" id="idm139656381902992" />naive Bayes classifiers) are capable of
              handling multiple classes directly. Others (such as Support Vector Machine classifiers or Linear
              classifiers) are strictly binary classifiers. However, there are various strategies that you can use to
              perform multiclass classification using multiple binary classifiers.</p>

            <p>For example, one way to create a system that can classify the digit images into 10 classes (from 0 to 9)
              is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-detector, and so
              on). Then when you want to classify an image, you get the decision score from each classifier for that
              image and you select the class whose classifier outputs the highest score. This is called the
              <em>one-versus-all</em> (OvA) strategy <a data-type="indexterm"
                data-primary="one-versus-all   (OvA)  strategy" id="idm139656381900656" />(also called
              <em>one-versus-the-rest</em>).</p>

            <p>Another strategy is to train a binary classifier for every pair of digits: one to distinguish 0s and 1s,
              another to distinguish 0s and 2s, another for 1s and 2s, and so on. This is called <a
                data-type="indexterm" data-primary="one-versus-one (OvO) strategy" id="idm139656381898528" />the
              <em>one-versus-one</em> (OvO) strategy. If there are <em>N</em> classes, you need to train <em>N</em> ×
              (<em>N</em> – 1) / 2 classifiers. For the MNIST problem, this means training 45 binary classifiers! When
              you want to classify an image, you have to run the image through all 45 classifiers and see which class
              wins the most duels. The main advantage of OvO is that each classifier only needs to be trained on the
              part of the training set for the two classes that it must distinguish.</p>

            <p>Some algorithms (such as <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)"
                id="idm139656381895312" />Support Vector Machine classifiers) scale poorly with the size of the training
              set, so for these algorithms OvO is preferred since it is faster to train many classifiers on small
              training sets than training few classifiers on large training sets. For most binary classification
              algorithms, however, OvA is preferred.</p>

            <p>Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass
              classification task, and it automatically runs OvA (except for SVM classifiers for which it uses OvO).
              Let’s try this with the <code>SGDClassifier</code>:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>  <code class="c"># y_train, not y_train_5</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([5], dtype=uint8)</code></pre>

            <p>That was easy! This code trains the <code>SGDClassifier</code> <a data-type="indexterm"
                data-primary="Scikit-Learn" data-secondary="SGDClassifier" id="idm139656381814000" />on the training set
              using the original target classes from 0 to 9 (<code>y_train</code>), instead of the 5-versus-all target
              classes (<code>y_train_5</code>). Then it makes a prediction (a correct one in this case). Under the hood,
              Scikit-Learn actually trained 10 binary classifiers, got their decision scores for the image, and selected
              the class with the highest score.</p>

            <p>To see that this is indeed the case, you can call the <code>decision_function()</code> method. Instead of
              returning just one score per instance, it now returns 10 scores, one per class:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">some_digit_scores</code> <code class="o">=</code> <code class="n">sgd_clf</code><code class="o">.</code><code class="n">decision_function</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">some_digit_scores</code>
<code class="go">array([[-15955.22627845, -38080.96296175, -13326.66694897,</code>
<code class="go">           573.52692379, -17680.6846644 ,   2412.53175101,</code>
<code class="go">        -25526.86498156, -12290.15704709,  -7946.05205023,</code>
<code class="go">        -10631.35888549]])</code></pre>

            <p>The highest score is indeed the one corresponding to class 5:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">argmax</code><code class="p">(</code><code class="n">some_digit_scores</code><code class="p">)</code>
<code class="go">5</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_clf</code><code class="o">.</code><code class="n">classes_</code>
<code class="go">array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_clf</code><code class="o">.</code><code class="n">classes_</code><code class="p">[</code><code class="mi">5</code><code class="p">]</code>
<code class="go">5</code></pre>
            <div data-type="warning" epub:type="warning">
              <h6>Warning</h6>
              <p>When a classifier is trained, it stores the list of target classes in its <code>classes_</code>
                attribute, ordered by value. In this case, the index of each class in the <code>classes_</code> array
                conveniently matches the class itself (e.g., the class at index 5 happens to be class 5), but in general
                you won’t be so lucky.</p>
            </div>

            <p>If you want to force ScikitLearn to <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.multiclass.OneVsOneClassifier" id="idm139656381656880" />use one-versus-one or
              one-versus-all, you can use the <code>OneVsOneClassifier</code> or <code>OneVsRestClassifier</code>
              classes. Simply create an instance and pass a binary classifier to its constructor. For example, this code
              creates a multiclass classifier using the OvO strategy, based on a <code>SGDClassifier</code>:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.multiclass</code> <code class="kn">import</code> <code class="n">OneVsOneClassifier</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ovo_clf</code> <code class="o">=</code> <code class="n">OneVsOneClassifier</code><code class="p">(</code><code class="n">SGDClassifier</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ovo_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ovo_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([5], dtype=uint8)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="nb">len</code><code class="p">(</code><code class="n">ovo_clf</code><code class="o">.</code><code class="n">estimators_</code><code class="p">)</code>
<code class="go">45</code></pre>

            <p>Training a <code>RandomForestClassifier</code> is <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.ensemble.RandomForestClassifier" id="idm139656381725136" />just as easy:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">forest_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">forest_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([5], dtype=uint8)</code></pre>

            <p>This time Scikit-Learn did not have to run OvA or OvO because Random Forest <span
                class="keep-together">classifiers</span> can directly classify instances into multiple classes. You can
              call <span class="keep-together"><code>predict_proba()</code></span> to get the list of probabilities that
              the classifier assigned to each instance for each class:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">forest_clf</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([[0.  , 0.  , 0.01, 0.08, 0.  , 0.9 , 0.  , 0.  , 0.  , 0.01]])</code></pre>

            <p>You can see that the classifier is fairly confident about its prediction: the 0.9 at the 5<sup>th</sup>
              index in the array means that the model estimates a 90% probability that the image represents a 5. It also
              thinks that the image could instead be a 2, a 3 or a 9, respectively with 1%, 8% and 1% probability.</p>

            <p>Now of <a data-type="indexterm" data-primary="classifiers" data-secondary="evaluating"
                id="idm139656381494384" />course you want to evaluate these classifiers. As usual, you want to use
              cross-validation. Let’s evaluate the <code>SGDClassifier</code>’s accuracy using the
              <code>cross_val_score()</code> function:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">cross_val_score</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">scoring</code><code class="o">=</code><code class="s">"accuracy"</code><code class="p">)</code>
<code class="go">array([0.8489802 , 0.87129356, 0.86988048])</code></pre>

            <p>It gets over 84% on all test folds. If you used a random classifier, you would get 10% accuracy, so this
              is not such a bad score, but you can still do much <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.preprocessing.StandardScaler" id="idm139656381559808" />better. For example,
              simply scaling the inputs (as discussed in <a data-type="xref"
                href="ch02.xhtml#project_chapter">Chapter 2</a>) increases <a data-type="indexterm"
                data-primary="classifiers" data-secondary="multiclass" data-startref="c3m" id="idm139656381558064" /><a
                data-type="indexterm" data-primary="multiclass classifiers" data-startref="mcc3"
                id="idm139656381556816" />accuracy above 89%:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">StandardScaler</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">scaler</code> <code class="o">=</code> <code class="n">StandardScaler</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_train_scaled</code> <code class="o">=</code> <code class="n">scaler</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">float64</code><code class="p">))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cross_val_score</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train_scaled</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">scoring</code><code class="o">=</code><code class="s">"accuracy"</code><code class="p">)</code>
<code class="go">array([0.89707059, 0.8960948 , 0.90693604])</code></pre>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Error Analysis">
          <div class="sect1" id="idm139656381451376">
            <h1>Error Analysis</h1>

            <p>Of <a data-type="indexterm" data-primary="classifiers" data-secondary="error analysis" id="c3ea" /><a
                data-type="indexterm" data-primary="error analysis" id="ea3" />course, if this were a real project, you
              would follow the steps in your Machine Learning project checklist (see Appendix B): exploring data
              preparation options, trying out multiple models, shortlisting the best ones and fine-tuning their
              hyperparameters using <code>GridSearchCV</code>, <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.model_selection.GridSearchCV" id="idm139656381430912" />and automating as much
              as possible, as you did in the previous chapter. Here, we will assume that you have found a promising
              model and you want to find ways to improve it. One way to do this is to analyze the types of errors it
              makes.</p>

            <p>First, you can look at the <a data-type="indexterm" data-primary="confusion matrix"
                id="cmat3" />confusion matrix. You need to make predictions using the <code>cross_val_predict()</code>
              function, <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.metrics.confusion_matrix()" id="idm139656381427456" /> <a data-type="indexterm"
                data-primary="Scikit-Learn" data-secondary="sklearn.model_selection.cross_val_predict()"
                id="idm139656381426352" />then call the <code>confusion_matrix()</code> function, just like you did
              earlier:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y_train_pred</code> <code class="o">=</code> <code class="n">cross_val_predict</code><code class="p">(</code><code class="n">sgd_clf</code><code class="p">,</code> <code class="n">X_train_scaled</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">conf_mx</code> <code class="o">=</code> <code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> <code class="n">y_train_pred</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">conf_mx</code>
<code class="go">array([[5578,    0,   22,    7,    8,   45,   35,    5,  222,    1],</code>
<code class="go">       [   0, 6410,   35,   26,    4,   44,    4,    8,  198,   13],</code>
<code class="go">       [  28,   27, 5232,  100,   74,   27,   68,   37,  354,   11],</code>
<code class="go">       [  23,   18,  115, 5254,    2,  209,   26,   38,  373,   73],</code>
<code class="go">       [  11,   14,   45,   12, 5219,   11,   33,   26,  299,  172],</code>
<code class="go">       [  26,   16,   31,  173,   54, 4484,   76,   14,  482,   65],</code>
<code class="go">       [  31,   17,   45,    2,   42,   98, 5556,    3,  123,    1],</code>
<code class="go">       [  20,   10,   53,   27,   50,   13,    3, 5696,  173,  220],</code>
<code class="go">       [  17,   64,   47,   91,    3,  125,   24,   11, 5421,   48],</code>
<code class="go">       [  24,   18,   29,   67,  116,   39,    1,  174,  329, 5152]])</code></pre>

            <p>That’s a lot of numbers. It’s often more convenient to look at an image representation of the confusion
              matrix, using <a data-type="indexterm" data-primary="Matplotlib" id="idm139656381296048" />Matplotlib’s
              <code>matshow()</code> function:</p>

            <pre data-type="programlisting" data-code-language="python"><code class="n">plt</code><code class="o">.</code><code class="n">matshow</code><code class="p">(</code><code class="n">conf_mx</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="n">plt</code><code class="o">.</code><code class="n">cm</code><code class="o">.</code><code class="n">gray</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

            <figure class="smallerfourtyfive">
              <div class="figure">
                <img src="mlst_03in02.png" alt="mlst 03in02" width="991" height="1023" />
                <h6 />
              </div>
            </figure>

            <p>This confusion matrix looks fairly good, since most images are on the main diagonal, which means that
              they were classified correctly. The 5s look slightly darker than the other digits, which could mean that
              there are fewer images of 5s in the dataset or that the classifier does not perform as well on 5s as on
              other digits. In fact, you can verify that both are the case.</p>

            <p>Let’s focus the plot on the errors. First, you need to divide each value in the confusion matrix by the
              number of images in the corresponding class, so you can compare error rates instead of absolute number of
              errors (which would make abundant classes look unfairly bad):</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="n">row_sums</code> <code class="o">=</code> <code class="n">conf_mx</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">norm_conf_mx</code> <code class="o">=</code> <code class="n">conf_mx</code> <code class="o">/</code> <code class="n">row_sums</code></pre>

            <p>Now let’s fill the diagonal with zeros to keep only the errors, and let’s plot the result:</p>

            <pre data-type="programlisting" data-code-language="python"><code class="n">np</code><code class="o">.</code><code class="n">fill_diagonal</code><code class="p">(</code><code class="n">norm_conf_mx</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">matshow</code><code class="p">(</code><code class="n">norm_conf_mx</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="n">plt</code><code class="o">.</code><code class="n">cm</code><code class="o">.</code><code class="n">gray</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

            <figure class="smallerfourtyfive">
              <div class="figure">
                <img src="mlst_03in03.png" alt="mlst 03in03" width="991" height="1023" />
                <h6 />
              </div>
            </figure>

            <p>Now you can clearly see the kinds of errors the classifier makes. Remember that rows represent actual
              classes, while columns represent predicted classes. The column for class 8 is quite bright, which tells
              you that many images get misclassified as 8s. However, the row for class 8 is not that bad, telling you
              that actual 8s in general get properly classified as 8s. As you can see, the confusion matrix is not
              necessarily symmetrical. You can also see that 3s and 5s often get confused (in both directions).</p>

            <p>Analyzing the confusion matrix can often give you insights on ways to improve your classifier. Looking at
              this plot, it seems that your efforts should be spent on reducing the false 8s. For example, you could try
              to gather more training data for digits that look like 8s (but are not) so the classifier can learn to
              distinguish them from real 8s. Or you could engineer new features that would help the classifier—for
              example, writing an algorithm to count the number of closed loops (e.g., 8 has two, 6 has one, 5 has
              none). Or you could preprocess the images (e.g., using Scikit-Image, Pillow, or OpenCV) to make some
              patterns stand out more, such as closed loops.</p>

            <p>Analyzing individual errors can also be a good way to gain insights on what your classifier is doing and
              why it is failing, but it is more difficult and time-consuming. For example, let’s plot examples of 3s and
              5s (the <code>plot_digits()</code> function just uses Matplotlib’s <code>imshow()</code> function; see
              this chapter’s Jupyter notebook for details):</p>

            <pre data-type="programlisting" data-code-language="python"><code class="n">cl_a</code><code class="p">,</code> <code class="n">cl_b</code> <code class="o">=</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">5</code>
<code class="n">X_aa</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[(</code><code class="n">y_train</code> <code class="o">==</code> <code class="n">cl_a</code><code class="p">)</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">y_train_pred</code> <code class="o">==</code> <code class="n">cl_a</code><code class="p">)]</code>
<code class="n">X_ab</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[(</code><code class="n">y_train</code> <code class="o">==</code> <code class="n">cl_a</code><code class="p">)</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">y_train_pred</code> <code class="o">==</code> <code class="n">cl_b</code><code class="p">)]</code>
<code class="n">X_ba</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[(</code><code class="n">y_train</code> <code class="o">==</code> <code class="n">cl_b</code><code class="p">)</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">y_train_pred</code> <code class="o">==</code> <code class="n">cl_a</code><code class="p">)]</code>
<code class="n">X_bb</code> <code class="o">=</code> <code class="n">X_train</code><code class="p">[(</code><code class="n">y_train</code> <code class="o">==</code> <code class="n">cl_b</code><code class="p">)</code> <code class="o">&amp;</code> <code class="p">(</code><code class="n">y_train_pred</code> <code class="o">==</code> <code class="n">cl_b</code><code class="p">)]</code>

<code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">8</code><code class="p">,</code><code class="mi">8</code><code class="p">))</code>
<code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">221</code><code class="p">);</code> <code class="n">plot_digits</code><code class="p">(</code><code class="n">X_aa</code><code class="p">[:</code><code class="mi">25</code><code class="p">],</code> <code class="n">images_per_row</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">222</code><code class="p">);</code> <code class="n">plot_digits</code><code class="p">(</code><code class="n">X_ab</code><code class="p">[:</code><code class="mi">25</code><code class="p">],</code> <code class="n">images_per_row</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">223</code><code class="p">);</code> <code class="n">plot_digits</code><code class="p">(</code><code class="n">X_ba</code><code class="p">[:</code><code class="mi">25</code><code class="p">],</code> <code class="n">images_per_row</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">224</code><code class="p">);</code> <code class="n">plot_digits</code><code class="p">(</code><code class="n">X_bb</code><code class="p">[:</code><code class="mi">25</code><code class="p">],</code> <code class="n">images_per_row</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

            <figure class="smallerfourtyfive">
              <div class="figure">
                <img src="mlst_03in04.png" alt="mlst 03in04" width="2153" height="2144" />
                <h6 />
              </div>
            </figure>

            <p>The two 5×5 blocks on the left show digits classified as 3s, and the two 5×5 blocks on the right show
              images classified as 5s. Some of the digits that the classifier gets wrong (i.e., in the bottom-left and
              top-right blocks) are so badly written that even a human would have trouble classifying them (e.g., the 5
              on the 1<sup>st</sup> row and 2<sup>nd</sup> column truly looks like a badly written 3). However, most
              misclassified images seem like obvious errors to us, and it’s hard to understand why the classifier made
              the mistakes it did.<sup><a data-type="noteref" id="idm139656381040496-marker"
                  href="ch03.xhtml#idm139656381040496">3</a></sup> The reason is that we used a simple
              <code>SGDClassifier</code>, which is a linear model. All it does is assign a weight per class to each
              pixel, and when it sees a new image it just sums up the weighted pixel intensities to get a score for each
              class. So since 3s and 5s differ only by a few pixels, this model will easily confuse them.</p>

            <p>The main difference between 3s and 5s is the position of the small line that joins the top line to the
              bottom arc. If you draw a 3 with the junction slightly shifted to the left, the classifier might classify
              it as a 5, and vice versa. In other words, this classifier is quite sensitive to image shifting and
              rotation. So one way to reduce the 3/5 confusion would be to preprocess the images to ensure that they are
              well centered and not too rotated. This will probably help reduce other errors as <a data-type="indexterm"
                data-primary="classifiers" data-secondary="error analysis" data-startref="c3ea"
                id="idm139656381037952" /><a data-type="indexterm" data-primary="error analysis" data-startref="ea3"
                id="idm139656381036704" /><a data-type="indexterm" data-primary="confusion matrix" data-startref="cmat3"
                id="idm139656381035760" />well.</p>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Multilabel Classification">
          <div class="sect1" id="idm139656381434448">
            <h1>Multilabel Classification</h1>

            <p>Until <a data-type="indexterm" data-primary="classifiers" data-secondary="multilabel" id="c3ml" /><a
                data-type="indexterm" data-primary="multilabel classifiers" id="mlc3" />now each instance has always
              been assigned to just one class. In some cases you may want your classifier to output multiple classes for
              each instance. For example, consider a face-recognition <a data-type="indexterm"
                data-primary="face-recognition" id="idm139656381030928" />classifier: what should it do if it recognizes
              several people on the same picture? Of course it should attach one tag per person it recognizes. Say the
              classifier has been trained to recognize three faces, Alice, Bob, and Charlie; then when it is shown a
              picture of Alice and Charlie, it should output [1, 0, 1] (meaning “Alice yes, Bob no, Charlie yes”). Such
              a classification system that outputs multiple binary tags is called a <em>multilabel classification</em>
              system.</p>

            <p>We won’t go into face recognition just yet, but let’s look at a simpler example, just for illustration
              purposes:</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.neighbors</code> <code class="kn">import</code> <code class="n">KNeighborsClassifier</code>

<code class="n">y_train_large</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_train</code> <code class="o">&gt;=</code> <code class="mi">7</code><code class="p">)</code>
<code class="n">y_train_odd</code> <code class="o">=</code> <code class="p">(</code><code class="n">y_train</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">1</code><code class="p">)</code>
<code class="n">y_multilabel</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">c_</code><code class="p">[</code><code class="n">y_train_large</code><code class="p">,</code> <code class="n">y_train_odd</code><code class="p">]</code>

<code class="n">knn_clf</code> <code class="o">=</code> <code class="n">KNeighborsClassifier</code><code class="p">()</code>
<code class="n">knn_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_multilabel</code><code class="p">)</code></pre>

            <p>This code creates a <code>y_multilabel</code> array containing two target labels for each digit image:
              the first indicates whether or not the digit is large (7, 8, or 9) and the second indicates whether or not
              it is odd. The next lines create a <code>KNeighborsClassifier</code> <a data-type="indexterm"
                data-primary="Scikit-Learn" data-secondary="sklearn.neighbors.KNeighborsClassifier"
                id="idm139656380980800" /><a data-type="indexterm" data-primary="k-Nearest Neighbors"
                id="idm139656380979856" />instance (which supports multilabel classification, but not all classifiers
              do) and we train it using the multiple targets array. Now you can make a prediction, and notice that it
              outputs two labels:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">knn_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">some_digit</code><code class="p">])</code>
<code class="go">array([[False,  True]])</code></pre>

            <p>And it gets it right! The digit 5 is indeed not large (<code>False</code>) and odd (<code>True</code>).
            </p>

            <p>There are many ways to evaluate a multilabel classifier, and selecting the right metric really depends on
              your project. For example, one approach is to measure the F<sub>1</sub> score for each individual label
              (or any other binary classifier metric discussed earlier), then simply compute the average score. This
              code computes the average F<sub>1</sub> score across <a data-type="indexterm" data-primary="Scikit-Learn"
                data-secondary="sklearn.model_selection.cross_val_predict()" id="idm139656380971120" /><a
                data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.metrics.f1_score()"
                id="idm139656380970144" />all labels:</p>

            <pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y_train_knn_pred</code> <code class="o">=</code> <code class="n">cross_val_predict</code><code class="p">(</code><code class="n">knn_clf</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_multilabel</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">f1_score</code><code class="p">(</code><code class="n">y_multilabel</code><code class="p">,</code> <code class="n">y_train_knn_pred</code><code class="p">,</code> <code class="n">average</code><code class="o">=</code><code class="s">"macro"</code><code class="p">)</code>
<code class="go">0.976410265560605</code></pre>

            <p>This assumes that all labels are equally important, which may not be the case. In particular, if you have
              many more pictures of Alice than of Bob or Charlie, you may want to give more weight to the classifier’s
              score on pictures of Alice. One simple option is to give each label a weight equal to its <em>support</em>
              (i.e., the number of instances with that target label). <a data-type="indexterm"
                data-primary="classifiers" data-secondary="multilabel" data-startref="c3ml" id="idm139656380952896" /><a
                data-type="indexterm" data-primary="multilabel classifiers" data-startref="mlc3"
                id="idm139656380766800" />To do this, simply set <code>average="weighted"</code> in the preceding
              code.<sup><a data-type="noteref" id="idm139656380765312-marker"
                  href="ch03.xhtml#idm139656380765312">4</a></sup></p>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Multioutput Classification">
          <div class="sect1" id="idm139656381034432">
            <h1>Multioutput Classification</h1>

            <p>The <a data-type="indexterm" data-primary="classifiers" data-secondary="multioutput" id="c3mo" /><a
                data-type="indexterm" data-primary="multioutput classifiers" id="moc3" />last type of classification
              task we are going to discuss here is called <em>multioutput-multiclass classification</em> (or simply
              <em>multioutput classification</em>). It is simply a generalization of multilabel classification where
              each label can be multiclass (i.e., it can have more than two possible values).</p>

            <p>To illustrate this, let’s build a system that removes noise from images. It will take as input a noisy
              digit image, and it will (hopefully) output a clean digit image, represented as an array of pixel
              intensities, just like the MNIST images. Notice that the classifier’s output is multilabel (one label per
              pixel) and each label can have multiple values (pixel intensity ranges from 0 to 255). It is thus an
              example of a multioutput classification system.</p>
            <div data-type="note" epub:type="note">
              <h6>Note</h6>
              <p>The line between <a data-type="indexterm" data-primary="classification versus regression"
                  id="idm139656380757728" /><a data-type="indexterm" data-primary="regression versus classification"
                  id="idm139656380756976" />classification and regression is sometimes blurry, such as in this example.
                Arguably, predicting pixel intensity is more akin to regression than to classification. Moreover,
                multioutput systems are not limited to classification tasks; you could even have a system that outputs
                multiple labels per instance, including both class labels and value labels.</p>
            </div>

            <p>Let’s start by creating the training and test sets by taking the MNIST images and adding noise to their
              pixel intensities using NumPy’s <code>randint()</code> function. The target images will be the original
              images:</p>

            <pre data-type="programlisting" data-code-language="python"><code class="n">noise</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">100</code><code class="p">,</code> <code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">),</code> <code class="mi">784</code><code class="p">))</code>
<code class="n">X_train_mod</code> <code class="o">=</code> <code class="n">X_train</code> <code class="o">+</code> <code class="n">noise</code>
<code class="n">noise</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">100</code><code class="p">,</code> <code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X_test</code><code class="p">),</code> <code class="mi">784</code><code class="p">))</code>
<code class="n">X_test_mod</code> <code class="o">=</code> <code class="n">X_test</code> <code class="o">+</code> <code class="n">noise</code>
<code class="n">y_train_mod</code> <code class="o">=</code> <code class="n">X_train</code>
<code class="n">y_test_mod</code> <code class="o">=</code> <code class="n">X_test</code></pre>

            <p>Let’s take a peek at an image from the test set (yes, we’re snooping on the test data, so you should be
              frowning right now):</p>

            <figure class="smallerfifty">
              <div class="figure">
                <img src="mlst_03in05.png" alt="mlst 03in05" width="1566" height="740" />
                <h6 />
              </div>
            </figure>

            <p>On the left is the noisy input image, and on the right is the clean target image. Now let’s train the
              classifier and make it clean this image:</p>

            <pre data-type="programlisting"
              data-code-language="python"><code class="n">knn_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_mod</code><code class="p">,</code> <code class="n">y_train_mod</code><code class="p">)</code>
<code class="n">clean_digit</code> <code class="o">=</code> <code class="n">knn_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([</code><code class="n">X_test_mod</code><code class="p">[</code><code class="n">some_index</code><code class="p">]])</code>
<code class="n">plot_digit</code><code class="p">(</code><code class="n">clean_digit</code><code class="p">)</code></pre>

            <figure class="smallertwenty">
              <div class="figure">
                <img src="mlst_03in06.png" alt="mlst 03in06" width="658" height="730" />
                <h6 />
              </div>
            </figure>

            <p>Looks close enough to the target! This concludes our tour of classification. Hopefully you should now
              know how to select good metrics for classification tasks, pick the appropriate precision/recall tradeoff,
              compare classifiers, and more generally build good classification systems for a variety of <a
                data-type="indexterm" data-primary="classifiers" data-secondary="multioutput" data-startref="c3mo"
                id="idm139656380918928" /><a data-type="indexterm" data-primary="multioutput classifiers"
                data-startref="moc3" id="idm139656380917680" />tasks.</p>
          </div>
        </section>













        <section data-type="sect1" data-pdf-bookmark="Exercises">
          <div class="sect1" id="idm139656380763984">
            <h1>Exercises</h1>
            <ol>
              <li>
                <p>Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set.
                  Hint: the <code>KNeighborsClassifier</code> <a data-type="indexterm" data-primary="Scikit-Learn"
                    data-secondary="sklearn.neighbors.KNeighborsClassifier" id="idm139656380688624" />works quite well
                  for this task; you just need to find good hyperparameter values (try a grid search on the
                  <code>weights</code> and <code>n_neighbors</code> hyperparameters).</p>
              </li>
              <li>
                <p>Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one
                  pixel.<sup><a data-type="noteref" id="idm139656380685648-marker"
                      href="ch03.xhtml#idm139656380685648">5</a></sup> Then, for each image in the training set, create
                  four shifted copies (one per direction) and add them to the training set. Finally, train your best
                  model on this expanded training set and measure its accuracy on the test set. You should observe that
                  your model performs even better now! This technique of artificially growing the training set is called
                  <em>data augmentation</em> or <em>training set expansion</em>.</p>
              </li>
              <li>
                <p>Tackle the <em>Titanic</em> dataset. A great place to start is on <a
                    href="https://www.kaggle.com/c/titanic">Kaggle</a>.</p>
              </li>
              <li>
                <p>Build a spam classifier (a more challenging exercise):</p>

                <ul>
                  <li>
                    <p>Download examples of spam and ham from <a
                        href="https://spamassassin.apache.org/old/publiccorpus/">Apache SpamAssassin’s public
                        datasets</a>.</p>
                  </li>
                  <li>
                    <p>Unzip the datasets and familiarize yourself with the data format.</p>
                  </li>
                  <li>
                    <p>Split the datasets into a training set and a test set.</p>
                  </li>
                  <li>
                    <p>Write a data preparation pipeline to convert each email into a feature vector. Your preparation
                      pipeline should transform an email into a (sparse) vector indicating the presence or absence of
                      each possible word. For example, if all emails only ever contain four words, “Hello,” “how,”
                      “are,” “you,” then the email “Hello you Hello Hello you” would be converted into a vector [1, 0,
                      0, 1] (meaning [“Hello” is present, “how” is absent, “are” is absent, “you” is present]), or [3,
                      0, 0, 2] if you prefer to count the number of occurrences of each word.</p>
                  </li>
                  <li>
                    <p>You may want to add hyperparameters to your preparation pipeline to control whether or not to
                      strip off email headers, convert each email to lowercase, remove punctuation, replace all URLs
                      with “URL,” replace all numbers with “NUMBER,” or even <a data-type="indexterm"
                        data-primary="stemming" id="idm139656380673248" />perform <em>stemming</em> (i.e., trim off word
                      endings; there are Python libraries available to do this).</p>
                  </li>
                  <li>
                    <p>Then try out several classifiers and see if you can build a great spam classifier, with both high
                      recall and high precision.</p>
                  </li>
                </ul>
              </li>

            </ol>

            <p>Solutions to these exercises are available in the online Jupyter notebooks at <a
                href="https://github.com/ageron/handson-ml2"><em
                  class="hyperlink">https://github.com/ageron/handson-ml2</em></a>.</p>
          </div>
        </section>







        <div data-type="footnotes">
          <p data-type="footnote" id="idm139656383696416"><sup><a
                href="ch03.xhtml#idm139656383696416-marker">1</a></sup> By default Scikit-Learn caches downloaded
            datasets in a <a data-type="indexterm" data-primary="Scikit-Learn"
              data-secondary="sklearn.datasets.fetch_openml()" id="idm139656383695856" />directory called
            <em>$HOME/scikit_learn_data</em>.</p>
          <p data-type="footnote" id="idm139656383480240"><sup><a
                href="ch03.xhtml#idm139656383480240-marker">2</a></sup> Shuffling may be a bad idea in some contexts—for
            example, if you are working on time series data (such as stock market prices or weather conditions). We will
            explore this in the next chapters.</p>
          <p data-type="footnote" id="idm139656381040496"><sup><a
                href="ch03.xhtml#idm139656381040496-marker">3</a></sup> But remember that our brain is a fantastic
            pattern recognition system, and our visual system does a lot of complex preprocessing before any information
            reaches our consciousness, so the fact that it feels simple does not mean that it is.</p>
          <p data-type="footnote" id="idm139656380765312"><sup><a
                href="ch03.xhtml#idm139656380765312-marker">4</a></sup> Scikit-Learn offers a few other averaging
            options and multilabel classifier metrics; see the documentation for more details.</p>
          <p data-type="footnote" id="idm139656380685648"><sup><a
                href="ch03.xhtml#idm139656380685648-marker">5</a></sup> You can use the <code>shift()</code> function
            from the <code>scipy.ndimage.interpolation</code> module. For example,
            <code>shift(image, [2, 1], cval=0)</code> shifts the image 2 pixels down and 1 pixel to the right.</p>
        </div>
      </div>
    </section>
  </div>



</body>

</html>